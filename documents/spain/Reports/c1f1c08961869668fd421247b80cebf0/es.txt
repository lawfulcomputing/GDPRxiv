                                                           Gabinete Jurídico

0059/2023

  

Tal y como recoge la Memoria de Análisis de Impacto Normativo (MAIN)
presentada junto con el Proyecto de Real Decreto,  la Ley 28/2022, de 21 de
diciembre, de fomento del ecosistema de las empresas emergentes prevé en
su articulado  la creación de entornos  controlados de pruebas por periodos
limitados de tiempo con el objetivo de evaluar la utilidad, la viabilidad y el
impacto de las innovaciones tecnológicas. En concreto, su art. 16.1 establece
que  [l]os poderes públicos promoverán, reglamentariamente, la creación de
entornos controlados, por períodos limitados de tiempo, para evaluar la utilidad,
la viabilidad y el impacto de innovaciones tecnológicas aplicadas a actividades
reguladas, a la oferta o provisión de nuevos bienes o servicios, a nuevas
formas de provisión o prestación de los mismos o a fórmulas alternativas para
su   supervisión   y   control   por   parte   de   las   autoridades   competentes,
especificando el apartado 4 de dicho precepto los principios a los que habrán
de ajustarse la creación y desarrollo de los entornos controlados de pruebas.

Igualmente, el Anexo I de la Proyecto de Real Decreto expone que la
Comisión Europea ha adoptado una propuesta de Reglamento por el que se
establecen   normas   armonizadas   en   materia   de   inteligencia   artificial
(Reglamento de Inteligencia Artificial) el 21 de abril de 2021. Dicha propuesta
de la Comisión tiene por objeto garantizar que los sistemas de inteligencia
artificial comercializados en el mercado de la Unión y utilizados en ella sean
seguros y respeten la legislación vigente relativa a los derechos fundamentales
y   los   valores   de   la   Unión,   garantizar   la   seguridad   jurídica   para   facilitar   la
inversión y la innovación en inteligencia artificial y mejorar la gobernanza y la
aplicación   efectiva   de   la   legislación   vigente   en   materia   de   derechos
fundamentales y seguridad, así como facilitar el desarrollo de un mercado único
de aplicaciones de inteligencia artificial que sean legales, seguras y fiables y
evitar la fragmentación del mercado, estableciéndose en el Anexo II un listado
de áreas de sistemas de inteligencia artificial que se consideran de alto riesgo
específico.

I

El   Proyecto   del   Real   Decreto   por   el   “que   establece   un   entorno
controlado de pruebas para el ensayo del cumplimiento de la propuesta de
Reglamento del Parlamento Europeo y del Consejo por el que se establecen
normas armonizadas en materia de inteligencia artificial” tiene como objeto,
como   se   establece   en   su   Artículo   1   “Objeto”   apartado   1,   comprobar   los
requisitos de diseño, validación y seguimiento que se deben establecer en el

c. Jorge Juan 6 
28001 Madrid

                                                                                                                                                             www.aepd.es

1

                                                           Gabinete Jurídico

desarrollo de sistemas de inteligencia artificial que puedan suponer riesgos
para la seguridad, la salud y los derechos fundamentales de las personas:

Artículo 1. Objeto
1.
El presente Real Decreto  tiene por objeto crear una experiencia
para comprobar los requisitos en el que participen diferentes entidades
elegidas mediante convocatoria pública, en la que se seleccionen, a
modo de ensayo, algunos sistemas de inteligencia artificial que puedan
suponer   riesgos   para   la   seguridad,   la   salud   y   los   derechos
fundamentales de las personas, con el objetivo de realizar la experiencia
que pueda posteriormente facilitar a todas las organizaciones europeas
la implementación de los principios que regirán el diseño, la validación y
el seguimiento de los sistemas de inteligencia artificial, y que ayudarán a
mitigar dichos riesgos.

Como establece el artículo 5 “Requisitos de elegibilidad para el acceso”
del Proyecto de Real Decreto, la participación en el entorno controlado de
pruebas está abierta a proveedores de sistemas de inteligencia artificial (en
adelante   “sistemas   IA”)   y,   en   calidad   de   usuarios   participantes,   personas
jurídicas que hagan uso de un sistema de inteligencia artificial de alto riesgo,
sistemas   de   propósito   general   o   modelos   fundacionales,   siempre   que   el
proveedor   de   dichos   sistemas   también   acceda   al   entorno   controlado   de
pruebas:

Artículo 5. Requisitos de elegibilidad para el acceso.
1.
La participación en el entorno controlado de pruebas está abierta
a   aquellos   proveedores   IA   y   usuarios   residentes   en   España   o   que
tengan un establecimiento permanente en España, o bien, sean parte de
una agrupación de entidades, donde el  representante de la agrupación
o apoderado único siendo integrante de ésta, sea la entidad solicitante y
cuyo domicilio o establecimiento principal se encuentre necesariamente
en territorio español a los efectos del art 9  del Real Decreto Legislativo
1/2010, de 2 de julio, por el que se aprueba el texto refundido de la Ley
de Sociedades de Capital. 
2.
Podrán acceder este entorno, en calidad de usuario participante,
las personas jurídicas privadas y entidades del sector público en España
que hagan uso de un sistema de inteligencia artificial de alto riesgo,
sistemas de propósito general, o modelos fundacionales, siempre que el
proveedor IA de ese sistema acceda también al entorno.

Por lo tanto, el entorno controlado de pruebas será relativo a “sistemas
de IA” y también al uso de sistemas de IA en tratamientos de determinados
usuarios.

II

c. Jorge Juan 6 
28001 Madrid

                                                                                                                                                             www.aepd.es

2

                                                           Gabinete Jurídico

Respecto al tratamiento de datos personales, el artículo 3 del Proyecto
Decreto establece en su apartado 3 la definición de “sistema de inteligencia
artificial”:

«Sistema de inteligencia artificial»: sistema diseñado para funcionar con
un cierto nivel de autonomía y que, basándose en datos de entradas
proporcionadas por máquinas o por   personas, infiere cómo lograr un
conjunto de objetivos establecidos utilizando estrategias de aprendizaje
automático   o   basadas   en   la   lógica   y   el   conocimiento,   y   genera
información   de   salida,   como   contenidos   (sistemas   de   inteligencia
artificial generativos), predicciones, recomendaciones o decisiones, que
influyan en los entornos con los que interactúa.

Hay que tener en cuenta que un sistema de IA estará formado por un
algoritmo   de   IA   y   por   otros   elementos   que   permitirán   la   implementación   y
operación efectiva del algoritmo, y que podrán condicionar los parámetros de
operación del sistema en múltiples aspectos. En definitiva, a través de datos
entrantes,   y   mediante   la   aplicación   del   algoritmo   del   sistema,   conseguir
información   de   salida,   con   la   finalidad   -agrega-   de   lograr   un   conjunto   de
objetivos   establecidos   utilizando   estrategias   de   aprendizaje   automático   o
basadas en la lógica y el conocimiento.

Por otro lado, el artículo 2, apartado 1, del Reglamento (UE) 2016/679
del Parlamento Europeo y del Consejo, de 27 de abril de 2016, relativo a la
protección de las personas físicas en lo que respecta al tratamiento de datos
personales y a la libre circulación de estos datos y por el que se deroga la
Directiva   95/46/CE   (Reglamento   general   de   protección   de   datos   o   RGPD)
establece el ámbito material de dicha norma  en los “tratamientos de datos
personales”, no en sistemas, tecnologías o infraestructuras técnicas:

1.   El presente Reglamento se aplica al tratamiento total o parcialmente
automatizado   de   datos   personales,   así   como   al   tratamiento   no
automatizado   de   datos   personales   contenidos   o   destinados   a   ser
incluidos en un fichero.

Un tratamiento se definirá, como establece el artículo 24, apartado 1 del

RGPD, por su naturaleza, el ámbito, el contexto y los fines del mismo:

Teniendo en cuenta la naturaleza, el ámbito, el contexto y los fines del
tratamiento, así como los riesgos de diversa probabilidad y gravedad
para los derechos y libertades de las personas físicas, el responsable
del tratamiento aplicará medidas técnicas y organizativas apropiadas a
fin de garantizar y poder demostrar que el tratamiento es conforme con
el presente Reglamento. Dichas medidas se revisarán y actualizarán
cuando sea necesario.

c. Jorge Juan 6 
28001 Madrid

                                                                                                                                                             www.aepd.es

3

                                                           Gabinete Jurídico

La naturaleza de un tratamiento supone la forma en que se implementa
dicho   tratamiento   de   forma   efectiva.   La   implementación   de   un   tratamiento
puede  dividirse  en  distintas   operaciones  de  tratamiento,   como  establece  el
Artículo 4.2 del RGPD:

«tratamiento»: cualquier operación o conjunto de operaciones realizadas
sobre datos personales o conjuntos de datos personales, ya sea por
procedimientos   automatizados   o   no,   como   la   recogida,   registro,
organización, estructuración, conservación, adaptación o modificación,
extracción, consulta, utilización, comunicación por transmisión, difusión
o cualquier otra forma de habilitación de acceso, cotejo o interconexión,
limitación, supresión o destrucción;

Las   operaciones   del   tratamiento   a   su   vez   pueden   ser   manuales   o
automatizadas, en todo o en parte. La implementación automatizada puede
realizarse utilizando distintos sistemas, como podrían ser sistemas móviles,
sistemas de almacenamiento local, sistemas en la Nube, sistemas de cifrado,
sistemas de videovigilancia y/o sistemas de IA.

En el caso que nos ocupa, y como se explica en el artículo publicado por
la AEPD Inteligencia Artificial: Sistema vs. tratamiento, medios vs. finalidad,1 de
abril de 2023, un mismo tratamiento puede incluir uno o varios sistemas de IA
en una implementación concreta de dicho tratamiento. Por lo tanto, en sí mismo
un sistema de IA no es un tratamiento, sino, en su caso y no siempre, podría
formar parte de un tratamiento.

III

Un sistema de IA podría no formar parte de un tratamiento de datos
personales ni en su diseño/desarrollo, como en su distribución por parte de un
proveedor, como en su operación en el marco de un tratamiento, o en su
evolución.

Por ejemplo, un sistema de IA operando en un entorno de producción
industrial, como podría ser en una cadena de montaje, en el que no se han
utilizado datos personales para su desarrollo y que no tiene ninguna interacción
o decisión en relación con operadores humanos no estaría involucrado en un
tratamiento del ámbito del material RGPD (en adelante tratamiento RGPD).

Sin embargo, existen diversos tratamientos RGPD en los que podrían
estar involucrado uno o varios sistema de IA como se ha explicado en la guía

1 https://www.aepd.es/es/prensa-y-comunicacion/blog/inteligencia-artificial-sistema-vs-
tratamiento-medio-vs-finalidad

c. Jorge Juan 6 
28001 Madrid

                                                                                                                                                             www.aepd.es

4

                                                           Gabinete Jurídico

de la AEPD Adecuación al RGPD de tratamientos que incorporan Inteligencia
Artificial 2 publicada en febrero de 2020.

En   primer   lugar,   un   sistema   de   IA   puede   estar   involucrado   en   un
tratamiento  RGPD  cuya finalidad  sea  el diseño y  desarrollo de un  sistema
automatizado. En el caso que se haya tomado la decisión de desarrollar dicho
sistema automatizado utilizando tecnología de IA, y que dicha tecnología de IA
requiera utilizar datos personales para su desarrollo (p. ej. un sistema de IA de
aprendizaje automático o determinados sistemas de reglas) estaríamos en el
supuesto de un tratamiento RGPD. Hay que llamar la atención de que en la
decisión   de   cómo   desarrollar   dicho   sistema   automatizado   se   podría   haber
optado por soluciones distintas a la IA o a la IA que requiere datos personales.

En segundo lugar, un sistema de IA podría contener en sí mismo datos
de personas identificadas o identificables. Esta circunstancia no se produce
siempre en un sistema de IA, ni es exclusiva de los sistemas de IA, pero podría
producirse. En ese caso, la distribución por un proveedor de un sistema de IA
con   dichas   características   podría   involucrar   la  comunicación   de   datos
personales, (esto es, tratamientos de datos personales) cuando existan datos
de personas identificables que se puedan extraer del sistema de IA.

En tercer lugar, un tratamiento puede implementar una o varias de sus
operaciones   utilizando  uno   o   varios  sistemas   de   IA   para   tratar   de   forma
automatizada datos personales, para tomar decisiones relativas a personas
físicas, o para perfilar a un individuo. Por ejemplo, cuando en un tratamiento de
contratación de personal se usa en las operaciones de selección un sistema de
IA para implementar un filtro previo de los curriculum vitae de más interés, lo
que   implicará   tratamiento   de   datos   personales   y   toma   de   decisiones
automatizadas con efectos jurídicos o que podrían afectar significativamente de
modo   similar.   Ya   sería   una   elección   del   responsable   añadir   o   no   una
supervisión humana cualificada en dicho tratamiento.

Finalmente, un cuarto  tratamiento  se puede producir cuando algunos
sistemas   IA   tienen   la   característica   de   que   pueden   evolucionar   durante   la
ejecución del tratamiento del responsable utilizando para ello datos personales
del tratamiento. Con relación al tratamiento de evolución de los sistemas IA se
podrían dar los siguientes casos: bien el tratamiento lo realiza un tercero para
cumplir sus propies fines, bien por dicho tercero para cumplir los fines del
responsable, o bien por el propio responsable para sus propios fines.

En definitiva, un sistema de IA se puede encontrar en el marco de cuatro
grupos de tratamiento: diseño/desarrollo, distribución, operación y evolución.
Cada uno de ellos podría implicar distintos responsables. Un mismo sistema de

2 https://www.aepd.es/sites/default/files/2020-02/adecuacion-rgpd-ia.pdf

c. Jorge Juan 6 
28001 Madrid

                                                                                                                                                             www.aepd.es

5

                                                           Gabinete Jurídico

IA podría estar en el marco de los cuatro tratamientos, de tres, de dos, de uno
o de ninguno.

IV

El Proyecto de Real Decreto establece en el Anexo II un listado de áreas
de sistemas de IA de alto riesgo, concepto que habría que matizar con relación
a la definición del alto riesgo en el RGPD.

Con relación al alto riesgo, en el artículo 35 del RGPD “Evaluación de
impacto   relativa   a   la   protección   de   datos”   (EIPD)   se   establece   que  el
responsable ha de establecer si un tratamiento es de alto riesgo para los
derechos   y   libertades   de   las   personas   físicas  atendiendo   a   la   naturaleza,
alcance, contexto y fines del tratamiento, en particular, si se utiliza nuevas
tecnologías. La existencia de un alto riesgo en un tratamiento se determina de
forma no exhaustiva en los apartados 35.3 y las listas del 35.4 del artículo 35
del RGPD, en los casos del artículo 32, apartado 2, o del Considerando 75 del
RGPD, en los casos del artículo 28.2 de la Ley Orgánica 3/2018, de 5 de
diciembre   de   Protección   de   Datos   Personales   y   garantía   de   los   derechos
digitales (LOPDGDD), en los casos y ejemplos de las Directrices WP248 del
Grupo del Artículo 29 (ahora Comité Europeo de Protección de Datos-CEPD),
en la normativa específica que exige una Evaluación de Impacto en materia de
protección de datos (EIPD), en los casos y condiciones específicas descritos en
las directrices publicadas por el CEPD para tratamientos específicos, en los
casos   y   condiciones   específicas   descritos   en   los   códigos   de   conducta   de
acuerdo con el artículo 40 y en los mecanismos de certificación de acuerdo con
el artículo 42 del RGPD.

En definitiva, la clasificación del riesgo establecida en el Proyecto de
Real Decreto complementa,  pero no desplaza, la evaluación del riesgo para
tratamientos de datos personales establecida en el RGPD. La complementa en
el   sentido   de   que   determina   el   alto   riesgo   de   aquellas   operaciones   de
tratamiento  que  usan  dicho  tipo  de  sistemas.  En  concreto,  en  los  distintos
tratamientos en los que se encuentre involucrado un sistema de IA habrá que
realizar una gestión del riesgo atendiendo no solo a la naturaleza de alguna de
sus   operaciones   (uno   o  varios   sistemas   de   IA),   sino   que   habrá   que   tener
adicionalmente en cuenta el riesgo para los derechos y libertades que implican
el uso conjunto de todos los sistemas que implementan el tratamiento, el
ámbito o extensión de dicho tratamiento, el contexto en el que se desenvuelve
y los fines, así como la incertidumbre que puede introducir el uso de nuevas
tecnologías.

V

En el Proyecto de Real Decreto se establece en el artículo 5 “Requisitos
de elegibilidad para el acceso”, antes referenciado, la participación de distintos
c. Jorge Juan 6 
                                                                                                                                                             www.aepd.es
28001 Madrid

6

                                                           Gabinete Jurídico

agentes,   como   son   los   proveedores   de   IA   y   los   usuarios   tanto   personas
jurídicas privadas como integrantes del sector público.

En   las   propuestas   presentadas  debe   definirse   de   forma   clara   las
posiciones jurídicas de cada uno de los intervinientes respecto de los
tratamientos   de   datos   personales,  ya   sea   bien   como   responsables,
corresponsables,   encargados   o   subencargados   del   tratamiento,   conforme
establece el RGPD, cuya observancia no es desplazada, sino reforzada por el
Proyecto de Real Decreto (art. 16, Protección de Datos Personales).

1.   Tanto   los   proveedores   IA   participantes   como   los   usuarios
participantes   en   el   entorno   controlado   de   pruebas   respetarán   las
disposiciones   de   protección   de   datos   aplicables.  El   régimen   de
protección de datos de carácter personal en las actuaciones que se
desarrollen en el marco de este entorno controlado de pruebas es
el previsto tanto en el  Reglamento  (UE)  679/2016, del Parlamento
Europeo y el Consejo, de 27 de abril de 2016, relativo a la protección de
las   personas   físicas   en   lo   que   respecta   al   tratamiento   de   datos
personales y a la libre circulación de estos datos (RGPD), como en la
Ley   Orgánica   3/2018,   de   5   de   diciembre,   de   Protección   de   Datos
Personales y Garantía de los Derechos Digitales (LOPDGDD), debiendo
quedar   todos   los   datos   personales   que   se   traten   en   los   sistemas
privados de los proveedores IA participantes o , en su caso, de los
usuarios participantes según corresponda para comprobar los requisitos
incluidos bajo dicha protección. 

2.   La  aceptación   de   participación   en   el   entorno   controlado   de
pruebas   implicará   reconocimiento   del   cumplimiento   de   la
legislación en materia de protección de datos.

VI

En el Proyecto de Real Decreto, en su artículo 1 “Objeto” apartado 1,
antes referenciado, se establece que el objetivo es extraer experiencia sobre
los principios que posteriormente se habrán aplicar a nivel europeo para el
diseño, validación y seguimiento de sistemas IA:

…el objetivo de realizar la experiencia que pueda posteriormente facilitar
a todas las organizaciones europeas la implementación de los principios
que regirán el diseño, la validación y el seguimiento de los sistemas de
inteligencia artificial, y que ayudarán a mitigar dichos riesgos.

Por otro lado, en el artículo 4 “Régimen Jurídico”, en su apartado 2, se
establece que no se exime a los sistemas IA del cumplimiento de su legislación
específica, no desde el diseño, sino una vez puesto en el mercado. Además,
siempre que no haya sido introducido previamente en dicho mercado:
c. Jorge Juan 6 
28001 Madrid

                                                                                                                                                             www.aepd.es

7

                                                           Gabinete Jurídico

En caso de que un sistema de inteligencia artificial esté regulado por
una legislación  sectorial específica  y no  haya  sido  introducido  en  el
mercado o puesto en servicio con carácter previo a la solicitud de su
participación en el entorno controlado de pruebas, su participación en él
no exime del cumplimiento de que el sistema de inteligencia artificial
deba superar la evaluación de conformidad de acuerdo con la legislación
específica una vez el sistema de inteligencia artificial sea puesto en el
mercado.

En este caso, cabe señalar que las provisiones del Real Decreto no
pueden   desplazar   las   obligaciones   de   cumplimiento   del   RGPD   y   la
LOPDGDD en los tratamientos en los que se involucra el sistema de IA. En
particular, que los tratamientos de datos personales han de estar adecuados
desde el diseño  de los mismos, lo que implica “antes” de su puesta en el
mercado. Esto es, no puede entenderse que un sistema IA que “no haya sido
introducido aún en el mercado” pueda adecuarse a la normativa de tratamiento
de datos personales “una vez que sea puesto en el mercado”, puesto que el
RGPD es normativa obligatoria “desde el diseño del sistema IA”.

Como la participación en el entorno controlado de pruebas no excluye la
obligación   del   cumplimiento   de   la   normativa   de   protección   de   datos,   por
razones de seguridad jurídica se debería hacer una mención expresa al artículo
16 del Proyecto de Real Decreto, modificado conforme a las observaciones
incluidas en el presente informe, e incluso su recogida de manera expresa en el
propio artículo 4.2 del Proyecto, o en un apartado a continuación específico.

VII

En el artículo 7 del Proyecto de Real Decreto “Solicitud de acceso al
entorno controlado de pruebas” se establece en su apartado 3 la obligación de
presentar   una   declaración   responsable   con   relación   al   cumplimiento   de   la
normativa relativa a la protección de datos personales:

3. Las solicitudes que se presenten deberán ir acompañadas de: una
memoria   técnica   que   deberá   contemplar   el   contenido   previsto   en   el
Anexo II; una declaración responsable que acredite el cumplimiento de
la normativa relativa a la Protección de Datos Personales; y de aquella
documentación que se estableciera en la convocatoria.

A diferencia de la memoria técnica, que se incluye en el Anexo II del
Real   Decreto,   la   declaración   responsable   no   aparece   en   el   mismo.   Por
seguridad   jurídica,   se   sugiere   que   el   texto   de   dicha   declaración   debería
aparecer en un Anexo del Real Decreto junto con un Anexo descriptivo de la
documentación acreditativa del principio de responsabilidad proactiva de igual
forma que la memoria técnica. En dicho anexo se deberá reflejar con nitidez,
c. Jorge Juan 6 
                                                                                                                                                             www.aepd.es
28001 Madrid

8

                                                           Gabinete Jurídico

entre   otros,   la   identificación   clara   de   los   tratamientos   y   de   los   roles
responsable/encargado en ellos con relación al diseño/desarrollo, distribución,
operación y evolución, las legitimaciones de los tratamientos y, en caso de alto
 la   superación
riesgo   del   tratamiento   de   acuerdo   con   el   RGPD,
favorablemente de la evaluación de impacto para la protección de datos
(EIPD).

VIII

El   artículo   8   del   Proyecto   de   Real   Decreto,   “Evaluación   de   las
solicitudes”, establece en su apartado 2 lo elementos de las solicitudes para el
acceso al entorno controlado de pruebas que serán evaluados:

2.
Se procederá a la evaluación de las solicitudes para el acceso al
entorno, evaluándose para cada uno de los sistemas de inteligencia
artificial recibidos, lo siguiente:

Grado de innovación o complejidad tecnológica del producto o

a)
servicio.

Grado de impacto social, empresarial o de interés público que

b)
presenta el sistema de inteligencia artificial propuesto.

Grado de explicabilidad y transparencia del algoritmo incluido en

c)
el sistema de inteligencia artificial presentado.

Alineamiento de la entidad y el sistema de inteligencia artificial

d)
con la Carta de Derechos Digitales del Gobierno de España.

Tipología   de   alto   riesgo   del   sistema   de   inteligencia   artificial,

e) 
buscando una representación variada de tipologías en la selección.
f)
 Cuando se trate de sistemas de inteligencia artificial de propósito
general, se evaluará también su potencial de ser transformados en un
sistema de inteligencia artificial de alto riesgo.

g) 
Cuando se trate de modelos fundacionales de inteligencia artificial
se   evaluará   la   capacidad   de   despliegue   y   utilización,   así   como   el
impacto relativo o absoluto en la economía y sociedad.

h) 
El   grado   de   madurez   del   sistema   de   inteligencia   artificial,
considerando que ha de estar lo suficientemente avanzado como para
ser puesto en servicio o en el mercado en el marco temporal del entorno
controlado   de   pruebas   o   a   su   finalización.   Se   buscará   una
representación   variada   de   madurez   de   los   sistemas   de   inteligencia
artificial.

c. Jorge Juan 6 
28001 Madrid

                                                                                                                                                             www.aepd.es

9

                                                           Gabinete Jurídico

i)

La calidad de la memoria técnica.

j)
El tamaño o tipología del proveedor IA solicitante, según número
de   trabajadores   o   volumen   de   negocios   anual,   valorándose
positivamente la condición de empresa emergente, pequeña o mediana
empresa   para   garantizar   una   mayor   diversidad   de   tipologías   de
empresas   participantes.   Se   buscará   una   representación   variada   de
tamaño y tipología de proveedor IA en la selección.

k) 
También se valorará positivamente la participación de entidades
del sector público, tanto en calidad de proveedor IA como en calidad de
usuario.

l)
Para el caso en que el sistema de inteligencia artificial esté sujeto
al cumplimiento de legislación sectorial específica y esté en el mercado,
se solicitará que se aporte un informe de la Autoridad Competente sobre
el correcto cumplimiento ésta. Si el informe es desfavorable, se podrá
entender que concurre un motivo para la denegación de la solicitud.

m) 
El plan de cumplimiento de legislación sectorial específica que se
haya ejecutado o diseñado para que el sistema de inteligencia artificial
en cuestión cumpla con la normativa en vigor.

En este sentido, y con relación a lo establecido y analizado en el artículo
7 del Proyecto de Real Decreto, se considera que, por seguridad jurídica, sería
necesario   que   en   el   procedimiento   de   evaluación   se   incluya   la   también   la
evaluación de la declaración responsable que acredite el cumplimiento de
la normativa relativa a la Protección de Datos Personales, y la evaluación
de   la   documentación   acreditativa   de   las   afirmaciones   que   debería
adjuntarse   a   la   declaración   responsable,   como   se   ha   indicado
anteriormente.

A su vez, en el apartado 2.d) del citado art. 8 se exige un [a]lineamiento
de la entidad y el sistema de inteligencia artificial con la Carta de Derechos
Digitales   del   Gobierno   de   España.  En   el   Titulo   X,   “Garantía   de   derechos
digitales” de la LOPDGDD (artículos 79 a 97) se establecen derechos digitales
con carácter de ley orgánica, exceptuando los artículos 79, 80, 81, 82, 88, 95,
96 y 97, que tienen carácter de ley ordinaria. Teniendo en cuenta la prevalencia
de la norma sobre una declaración sin carácter normativo, como la Carta de
Derechos Digitales del Gobierno de España, se sugiere que se haga también
referencia  y   de   forma   preferente   a   dicho  título   de   la  normativa   de   la
LOPDGDD.

IX

c. Jorge Juan 6 
28001 Madrid

                                                                                                                                                             www.aepd.es

10

                                                           Gabinete Jurídico

En el artículo 12, “Desarrollo de las pruebas por los participantes”, del

Proyecto de Real Decreto, en el apartado 2, se establece:

La adaptación de estos sistemas de inteligencia artificial al cumplimiento
de   los   requisitos  no   implica  riesgos   potenciales   en   materia   de
protección de consumidores, de usuarios y de terceros que pudieran
verse afectados.

Tal y como está redactado dicho apartado, se podría entender que se
realiza en el Real Decreto una evaluación del riesgo apriorística (“no implica
riesgos”), salvo que se deba interpretar en el sentido de que la adaptación de
dichos sistemas de IA no debería implicar riesgos. Si fuese este último caso,
debería aclararse la redacción. Si no fuera este el caso, y como se ha expuesto
en   el   principio   de   este   informe,   el   Real   Decreto   no   podría   realizar   una
evaluación apriorística del riesgo para los derechos y libertades que establece
el RGPD de un tratamiento en el que está (o esté) involucrado un sistema de
IA. Corresponde a los responsables de los tratamientos, conforme al RGPD, el
análisis de los riesgos y la evaluación de los impactos en materia de protección
de datos (arts. 24, 25, 32, 35 etc. RGPD) adoptando las medidas necesarias, y
demostrando   incluso   la   conformidad   con   el   presente   Reglamento   de   las
medidas previstas para afrontar los riesgos teniendo en cuenta los derechos e
intereses   legítimos   de   los   interesados   y   de   otras   personas   afectadas   (art.
35.7.d) RGPD).

El art. 16 del Proyecto de Real Decreto, Protección de Datos Personales,

establece:

X

1.   Tanto   los   proveedores   IA   participantes   como   los   usuarios
participantes   en   el   entorno   controlado   de   pruebas   respetarán   las
disposiciones   de   protección   de   datos   aplicables.   El   régimen   de
protección de datos de carácter personal en las actuaciones que se
desarrollen en el marco de este entorno controlado de pruebas es el
previsto tanto en el Reglamento (UE) 679/2016, del Parlamento Europeo
y el Consejo, de 27 de abril de 2016, relativo a la protección de las
personas físicas en lo que respecta al tratamiento de datos personales y
a la libre circulación de estos datos (RGPD), como en la Ley Orgánica
3/2018,   de   5   de   diciembre,   de   Protección   de   Datos   Personales   y
Garantía de los Derechos Digitales (LOPDGDD), debiendo quedar todos
los  datos  personales  que  se  traten en  los  sistemas  privados  de  los
proveedores   IA   participantes   o   ,   en   su   caso,   de   los   usuarios
participantes según corresponda para comprobar los requisitos incluidos
bajo dicha protección.

c. Jorge Juan 6 
28001 Madrid

                                                                                                                                                             www.aepd.es

11

                                                           Gabinete Jurídico

El   principio   de   licitud   del   tratamiento   (Artículo   5.1.a)   RGPD),   el   de
responsabilidad proactiva (Artículo 5.2 del RGPD) y el principio de protección
de datos desde del diseño (Artículo 25.1 del RGPD), establecen, como ya se
ha   mencionado,   que   el   cumplimiento   del   RGPD   en   tratamientos   de   datos
personales debe establecer y garantizarse antes del inicio del tratamiento.

Por otro lado, el principio de minimización (Artículo 5.1.c del RGPD) y el
principio de conservación (Artículo 5.1.e del RGPD) establecen que los datos
deben ser adecuados, pertinentes y limitados a lo necesario en relación con los
fines para los que son tratados, y mantenidos de forma que se permita la
identificación de los interesados durante no más tiempo del necesario para los
fines del tratamiento de  los datos personales;  los datos personales podrán
conservarse   durante   períodos   más   largos   siempre   que   se   traten
exclusivamente con fines de archivo en interés público, fines de investigación
científica o histórica o fines estadísticos, de conformidad con el artículo 89,
apartado 1 RGPD, sin perjuicio de la aplicación de las medidas técnicas y
organizativas apropiadas que impone el presente Reglamento a fin de proteger
los derechos y libertades del interesado.

En este caso, la adecuación de los datos personales utilizados en los
tratamientos,   por   ejemplo,   para   el   tratamiento   de   desarrollo   mediante
entrenamiento de un sistema de IA, debe evaluarse con anterioridad al inicio
del tratamiento, y acreditarse en su caso adecuadamente por terceros. Si no
fuera   posible   en   algún   caso   excepcional,   lo   que   habría   que   justificar
adecuadamente previamente al inicio del proyecto, habría que determinar que
no se ha implementado un tratamiento que por diseño impide realizar dicha
evaluación.   Esto,   en   su   caso,   podría   suponer   un   incumplimiento   de   la
normativa de protección de datos. En otro caso, habría que establecer, entre
otros, la legitimación de esa conservación, la gestión adecuada del riesgo para
los derechos y libertades, y la aplicación de medidas de privacidad como las de
seleccionar una muestra significativa, si es posible anonimizada, con plazos
específicos de conservación, o con datos sintéticos.

Asimismo,   en   el   marco   del   RGPD   se   tendrá   que   evaluar   si   con   la
operación del sistema de IA en un tratamiento IA se preserva el principio de
exactitud   (Artículo  5.1.d   del  RGPD)   de   las  decisiones,  perfilados   o  valores
inferidos. En este caso, aplica lo manifestado en el apartado anterior.

Por lo tanto, la redacción del artículo debería aclararse en el sentido de
que todos los tratamientos de datos personales realizados en el marco del
entorno   controlado   de   prueba   tienen   que   cumplir   con   la   normativa   de
protección de datos, en particular, el RGPD y la LOPDGDD, y la normativa
sectorial   aplicable.   Además,   dicha   conformidad   ha   de   garantizarse   con
anterioridad a la realización de los tratamientos de datos personales.

c. Jorge Juan 6 
28001 Madrid

                                                                                                                                                             www.aepd.es

XI

12

                                                           Gabinete Jurídico

El Artículo 29 del Proyecto “Participación de personas jurídicas privadas
y entidades del sector público como usuarias de un sistema de inteligencia
artificial” establece en el apartado 2:

La persona jurídica privada o entidad del sector público, cuando actúen
como usuarios participantes deberán colaborar implantando las medidas
especificadas en las guías que el órgano competente proporcione para
el  seguimiento  tras la  puesta  en  marcha  del  sistema  de  inteligencia
artificial.

En la medida en que el tratamiento en el que se incluya el sistema de IA
trate datos personales, decisiones sobre personas o perfilados, se debe definir
la posición jurídica RGPD del usuario con relación al desarrollador, proveedor
del   sistema   o   evolucionador   del   sistema.   Dicha   circunstancia   es   oportuna
reflejarla en dicho apartado haciendo, además, una referencia a lo observado
sobre   la   Declaración   Responsable   y   la   acreditación   de   lo   declarado.   Con
relación   a   la   evolución   del   sistema   de   IA,   los   roles   son   más   complejos,
podríamos entrar en un escenario de comunicación responsable-responsable o
de situaciones responsable-encargado, en cuyo caso ha de tenerse en cuenta
específicamente las previsiones del art. 28.

XII

En el Anexo II “Listado de áreas de sistemas de inteligencia artificial de
alto riesgo específicos” se enumera un conjunto de sistemas IA que el Real
Decreto establece de alto riesgo.

Como se ha señalado en el apartado IV de este informe, la clasificación
del riesgo establecida en el Proyecto de Real Decreto complementa, pero no
desplaza,   la   evaluación   del   riesgo   para   tratamientos   de   datos   personales
establecida en el RGPD. En concreto, en los distintos tratamientos de datos
personales en los que se encuentre involucrado un sistema de IA habrá que
realizar una gestión del riesgo atendiendo no solo a la naturaleza de alguna de
sus operaciones (uno o varios sistemas de IA), sino que hay que tener en
cuenta el riesgo para los derechos y libertades que implican el uso conjunto
de todos los sistemas que implementan el tratamiento, el ámbito o extensión de
dicho tratamiento, el contexto en el que se desenvuelve y los fines, así como la
incertidumbre que puede introducir el uso de nuevas tecnologías. En la medida
que el tratamiento sea de alto riesgo del tratamiento de acuerdo con el RGPD,
será necesaria la superación de la evaluación de impacto para la protección de
datos (EIPD) previa a la ejecución de dicho tratamiento.

Todo ello sin perjuicio de que alguno de los sistemas de alto riesgo que
podrían participar en el entorno controlado de prueba, como el descrito en el
apartado 7.a “sistemas de inteligencia artificial destinados a su uso por las
c. Jorge Juan 6 
                                                                                                                                                             www.aepd.es
28001 Madrid

13

                                                           Gabinete Jurídico

autoridades   públicas   competentes   o   en   su   nombre   como   polígrafos   y
herramientas similares, o para detectar el estado emocional de una persona
física;” en el que no hay una restricción de su uso a su empleo para la finalidad
de,   por   ejemplo,   investigación   de   delitos   penales,   o   el   8.a   “sistemas   de
inteligencia artificial destinados a su uso por una autoridad judicial o en su
nombre para la interpretación de hechos o de la ley para aplicar la ley a un
conjunto concreto de hechos” deberían tener un análisis previo de la licitud
del tratamiento.

XIII

En   el   Anexo   IV   del   proyecto   de   Real   Decreto,   dentro   de   la
“Documentación Técnica a presentar a la finalización de la implantación de los
requisitos”, en el punto 3 se establece:

Información detallada sobre la supervisión, el funcionamiento y el control
del sistema de inteligencia artificial, en particular con respecto a: sus
capacidades y limitaciones de rendimiento, incluyendo los grados de
precisión para las personas o grupos de personas específicos sobre los
que   se   pretende   utilizar   el   sistema   y   el   nivel   general   de   precisión
previsto en relación con su finalidad su finalidad prevista; las fuentes de
riesgo para la salud y la seguridad, los derechos fundamentales y la
discriminación  en  vista de  la  de la  finalidad  prevista  del  sistema  de
inteligencia artificial; las medidas de supervisión humana necesarias de
conformidad   con   el   artículo   11   y   las   guías   ofrecidas   por   el   órgano
competente   a  tal  efecto,  incluidas  las   medidas   técnicas  establecidas
para facilitar la interpretación de la información de salida de los sistemas
de   inteligencia   artificial   por   parte   de   los   usuarios   del   sistema;   las
especificaciones sobre los datos de entrada según proceda;

Con   relación   a   los   tratamientos   de   datos   personales,   los   aspectos
señalados en dicho punto deberían establecerse en función del impacto que
puedan tener en los tratamientos del usuario, o de las finalidades previstas y
contextos   específicos   de   operación,   para   los   que   se   valida   el  sistema.   En
particular,   las   métricas   de   rendimiento,   que   deben   ser   seleccionadas   de
acuerdo con  las finalidades  y contextos de operación y ser  evaluadas  con
relación al riesgo que pueden implicar para los derechos y libertades de los
ciudadanos en el marco de un tratamiento de datos personales realizados por
un usuario.

XIV

Finalmente, y a tenor de todo lo expuesto hasta el momento, no se
comparte, y en opinión de esta Agencia debería modificarse para expresar que
lo tratamientos derivados del proyecto pueden considerarse de alto riesgo en
materia   de   protección   de   datos,   y   establecer   cómo   se   considera   esta
c. Jorge Juan 6 
                                                                                                                                                             www.aepd.es
28001 Madrid

14

                                                           Gabinete Jurídico

circunstancia en el texto, lo expresado en el apartado 8,  Consideración de
otros impactos, de la MAIN, que dice:

No   existen   otros   impactos.   Ya   que   no   se   van   a   acceder   a   datos
personales facilitados por las empresas y, en todo caso, se respetará la
normativa específica relativa a Protección de Datos. (…)

Precisamente, el riesgo no sólo ocurriría “si se accediese a los datos
facilitados por las empresas”, sino está en que las empresas acceden a datos
“de alto riesgo”, como responsables, de los interesados. Ciertamente, como se
ha expuesto, el Real Decreto no puede eximir del cumplimiento de la normativa
de protección de datos, y desde el diseño, pero eso no significa que en esos
tratamientos   no   se   den   algunos   “de   alto   riesgo”   (en   concreto,   todos   los
previstos en el Anexo II, desde la perspectiva del proyecto de Real Decreto),
sino también los que resulten tener tal consideración de la aplicación del RGPD
directamente.

c. Jorge Juan 6 
28001 Madrid

                                                                                                                                                             www.aepd.es

15

