

L'appello del Garante della privacy. Servono regole più severe ma anche una nuova cultura
Intervista a Pasquale Stanzione, Presidente del Garante per la protezione dei dati personali
(di Michela Allegri, Il Messaggero, 16 gennaio 2024)
Rendere più celeri ed efficaci le procedure per la rimozione di contenuti lesivi e pericolosi, ma anche un’educazione alla rete e ai social, soprattutto per i più giovani, perché è necessario essere consapevoli della portata «potenzialmente fatale»,di ogni singolo post. Dopo il suicidio di Giovanna Pedretti, la ristoratrice di Sant’Angelo Lodigiano, il Garante della privacy, Pasquale Stanzione, parla dei rischi del web e delle possibili soluzioni.
Pensa serva una stretta nella gestione dei social e della rete?
«La violenza, anche “solo” verbale, sui social è una vera e propria emergenza democratica, ciò che rischia di rendere la rete lo spazio elettivo non già per la promozione dei diritti e delle libertà ma, al contrario, per la loro violazione. Di fronte a fenomeni di questa portata, la tentazione dell’approccio sanzionatorio e repressivo è forte, ma non sempre risolutiva. I contenuti diffamatori, istigativi di odio e discriminazione hanno rilevanza anche penale, eppure sono molto, troppo frequenti. Il diritto può sanzionare, può attenuare il danno (ad esempio con la rimozione dei contenuti illeciti), può anche in certa misura prevenire con la deterrenza, ma di fronte a fenomeni così pervasivi e rilevanti è necessario un mutamento culturale. Bisogna anzitutto educare: alla rete, alla relazione e alla relazione in rete, che ha delle sue caratteristiche peculiari. Il post diffamatorio ha un’attitudine alla diffusività, alla condivisione virale, alla persistenza e alla tendenziale ingovernabilità che non ha, certo, nessun tipo di diffamazione, vessazione, ingiuria off-line. Di questo, del potere potenzialmente fatale di ogni singolo click, dobbiamo essere consapevoli, a tutte le età».
In rete e sui social come funzionano i controlli relativi ai post? Mi riferisco in particolare alle campagne di odio, alla veridicità di informazioni diffuse, o ai messaggi degli hater.
«La moderazione dei contenuti è un’attività gestita essenzialmente, in via preventiva o successiva (a seguito cioè di richiesta del soggetto interessato), dalle piattaforme, con il rischio che ne consegue di una loro sostanziale autodichia. Tra i rischi del capitalismo delle piattaforme vi è, in primo luogo, quello di delegare loro la definizione del perimetro dei diritti della persona, agendo sul bilanciamento tra dignità e libertà di espressione. L’Europa ha tuttavia introdotto un’importante forma di responsabilizzazione delle piattaforme, anche rispetto alla moderazione dei contenuti, con il Digital Services Act, che potrà rivelarsi proficuo anche da questo punto di vista, per evitare gli opposti estremismi dell’anomia e della censura».
Quali potrebbero essere delle soluzioni per rendere i social più sicuri?
«Di fronte a fenomeni di tale complessità è necessario un approccio integrato, che coniughi norme, pedagogia, sensibilizzazione culturale. Una soluzione utile potrebbe intanto essere l’introduzione (proposta nella scorsa legislatura) di una procedura speciale per la rimozione, da parte del Garante, di contenuti istigativi ad atti suicidari o autolesionisti, così da ridurne il potenziale diffusivo. Si pensi all’esito fatale di certe challenge».
Quale impatto può avere una campagna di odio social su un soggetto debole? Quali sono i soggetti più a rischio?
«Le vittime elettive di un uso violento della rete sono generalmente i soggetti più fragili, per condizione sociale o personale, generalmente privi delle risorse, anzitutto psicologiche e culturali, necessarie ad affrontare il trauma della “gogna” del web. È significativo che l’ordinamento accordi una tutela rafforzata, anche sotto questo profilo, ai minori, la cui personalità, ancora in formazione, può subire i danni maggiori dall’uso distorto della rete. Dopo il suicidio di Carolina Picchio, la prima vittima accertata di cyberbullismo in Italia, il legislatore ha, infatti, introdotto una procedura speciale, attivabile anche dallo stesso minore ultraquattordicenne, per la rimozione dei contenuti lesivi, affidata in ultima istanza al Garante, con la celerità imposta dai tempi contratti del web. Una procedura per certi versi simile è stata introdotta per il revenge porn: altra insidia della rete che purtroppo colpisce anche, e sempre più spesso, i minori. Sono due esempi di soluzioni normative non repressive, ma attente alle vittime che, forse, potrebbero essere estese ad altri ambiti».
Quali sono attualmente le conseguenze in caso di recensioni false, post offensivi e minacce online?
«I contenuti lesivi possono presentare un diverso grado di illiceità: da quella penale, come post diffamatori, apologetici o istigativi all’odio e alla discriminazione, a quella civile, ad esempio per lesione del diritto all’immagine, fino a quella amministrativa ad esempio nel caso di contenuti realizzati mediante trattamento illegittimo di dati personali. Vi sono poi sanzioni “privatistiche” applicate dalle piattaforme, come l’oscuramento dell’account, ad esempio nel caso di contrarietà del contenuto rispetto alle policies aziendali. Il caso più noto è, per gli Usa, la sospensione dei profili social di Donald Trump a seguito degli eventi di Capitol Hill e, per l’Italia, le numerose chiusure dei profili di alcuni movimenti politici per la pubblicazione di contenuti istigativi all’odio e alla discriminazione etnica».
È possibile sporgere denuncia in questi casi, o inviare una segnalazione al Garante?
«Le competenze peculiari del Garante riguardano, oltre al trattamento illegittimo dei dati personali, anche l’oblio, il revenge porn e il cyberbullismo. Per gli ultimi due casi è prevista una procedura speciale che, in estrema sintesi, consente di disporre il blocco del caricamento dei contenuti nel primo caso e la richiesta di cancellazione degli stessi nel secondo, in 48 ore. Si tratta di due tutele particolarmente importanti, perché incentrate, più che sulla sanzione dell’autore, di competenza prevalentemente dell’autorità giudiziaria, sulla protezione della vittima e sulla prevenzione dei danni ulteriori che la permanenza, in rete, di contenuti lesivi, può determinare. Una forma innovativa di “diritto mite” di cui il web ha sempre più bisogno».

