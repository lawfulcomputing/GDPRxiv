

Bene l'Al Act ma la strada è lunga: serve rapidità e un'Autorità indipendente
Intervento di Guido Scorza, componente del Garante per la protezione dei dati personali
(MF, 13 dicembre 2023)
Le Istituzioni europee, nei giorni scorsi, hanno trovato un accordo politico sull’AI Act, il Regolamento europeo destinato a governare la progettazione, lo sviluppo, la produzione, la distribuzione e l’utilizzo di servizi e dispositivi basati sull’intelligenza artificiale.
Si sbaglierebbe, tuttavia, a parlare di “approvazione” del Regolamento sull’intelligenza artificiale perché la strada è ancora lunga e, per quanto improbabili, non possono escludersi incidenti di percorso.
È stato certamente fatto un passo importante verso una regolamentazione “forte” dell’impatto dell’intelligenza artificiale sulla società e questa è una buona notizia. Troppo presto però per esprimere giudizi che non rischino di essere smentiti nei prossimi mesi, quelli che ci separano dalla messa a punto e dalla definitiva approvazione del testo e, poi, più avanti, da una serie di scelte che il provvedimento europeo sembrerebbe rimettere alla discrezionalità dei singoli Paesi membri.
Il diavolo che è sempre nei dettagli, infatti, nel caso dei provvedimenti normativi è abilissimo a nascondersi tra le pieghe, tra le parole e, talvolta – non è un’iperbole persino tra i segni della punteggiatura.
Bene, quindi, l’entusiasmo con il quale in tutta Europa si è salutato l’epilogo positivo del c.d. trilogo ma, ora, guai a abbassare la guardia, rallentare il ritmo – anche perché la fine della legislatura è vicina - e, soprattutto, guai a considerare chiusa la partita perché c’è ancora tanto lavoro da fare e, soprattutto, ci vorranno due anni dalla sua definitiva approvazione e entrata in vigore prima che il Regolamento sia davvero legge, direttamente applicabile in tutta Europa.
Sui tanti motivi che ispirano un cauto ottimismo si è già scritto molto anche in ragione della comprensibile soddisfazione con la quale le istituzioni europee le hanno presentate al mondo.
Vale quindi la pena sottolineare alcuni profili che suggeriscono, invece, prudenza e attenzione nelle scelte ancora sul tavolo. In questa prospettiva, uno degli aspetti più delicati concerne l’uso da parte dei Governi dei dispositivi e servizi basati sull’intelligenza artificiale in particolare per fini di polizia e giustizia.
Non è un segreto che al riguardo la tensione nella fase finale dei negoziati sia stata altissima: alcuni Governi, incluso il nostro, hanno difeso fino all’ultimo l’esigenza di riservarsi un ampio margine di azione nell’uso dell’AI per il perseguimento dei propri scopi dal contrasto al crimine, all’ordine pubblico, passando per la giustizia. Insomma, hanno difeso l’idea che, nel pubblico, la legittimità e nobiltà dei fini possa legittimare il ricorso a mezzi diversamente intelligenti e capaci di supportare il raggiungimento di taluni obiettivi anche a costo di sacrifici importanti in termini di diritti e libertà.
Alla fine, fortunatamente, questa tesi non ha retto e le istituzioni europee, Parlamento in testa, hanno mantenuto il punto lasciando, semplicemente, spazio a alcune eccezioni.
Ora, naturalmente, la definizione di queste eccezioni è fondamentale per scongiurare il rischio che definizioni troppo lasche o troppo aperte alla discrezionalità dei singoli Paesi finiscano con il frustrare il principio che è stato fissato e con il far rientrare dalla finestra ciò che si è tenuto fuori dalla porta.
In Europa non si può e non si deve cedere all’idea secondo la quale tutto ciò che è tecnologicamente possibile debba considerarsi anche giuridicamente legittimo e democraticamente sostenibile. Farlo significherebbe rinunciare a conquiste ultracentenarie in fatto di diritti e libertà fondamentali.
Un’altra incertezza rilevante rimasta a quanto pare sui tavoli del negoziato riguarda l’identificazione, a livello nazionale, del soggetto deputato a vigilare sull’applicazione delle nuove regole.
Qui vale la pena essere molto diretti, a costo di urtare la sensibilità di qualcuno: questo soggetto deve essere un’Autorità indipendente tanto dai mercati che dai Governi perché entrambi saranno utilizzatori abituali di servizi e sistemi di intelligenza artificiale e entrambi potranno trovarsi a violare le nuove regole, cedendo alla tentazione tecnologica e anteponendo il risultato al rispetto dei diritti e delle libertà.
Un’agenzia governativa non potrebbe, in nessun caso, disporre della necessaria indipendenza specie dall’Esecutivo e rischierebbe di non essere un arbitro sufficientemente imparziale. Questo, naturalmente, non vuol dire che non possa pensarsi a un’agenzia di governo per la promozione dell’uso lecito dell’intelligenza artificiale, lasciando, tuttavia, a un’Autorità indipendente il compito di vigilare, poi, sul rispetto delle regole.
Altra questione importante riguarda infine il calendario dell’entrata in vigore dell’AI Act e della sua approvazione finale.
Nel migliore degli scenari perché le nuove regole siano definitivamente approvate e diventino direttamente applicabili in tutti i Paesi dell’Unione, ci vorrà la primavera del 2026.
Oltre due anni che corrispondono, al ritmo attuale di sviluppo nel settore dell’intelligenza artificiale, a un’era geologica nel corso della quale ci troveremo a confrontarci con applicazioni e servizi basati sull’AI, oggi semplicemente inimmaginabili.
È quindi indispensabile affrettarsi a identificare, almeno a livello nazionale, il soggetto o i soggetti al quale o ai quali verrà affidata l’applicazione delle nuove regole, delegandoli a governare, medio tempore, il settore, tenendo presenti i principi che saranno frattanto declinati nel testo del nuovo regolamento.
Fallire questo obiettivo potrebbe significare ritrovarci tra un paio d’anni con le regole migliori al mondo ma troppo tardi per avere qualsiasi chance concreta di orientare l’intelligenza artificiale, nel pubblico come nel privato, nella direzione della massimizzazione del benessere collettivo.

