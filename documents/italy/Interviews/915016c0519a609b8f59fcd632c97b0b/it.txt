

Giusto mettere un argine alla sorveglianza di massa
Intervista a Guido Scorza, Componente del Garante per la protezione dei dati personali
(di Raffaele D'Ettorre, Il Mattino, 9 dicembre 2023)
Il testo finale è un compromesso a ogni riga, e non poteva essere altrimenti trattandosi di uno degli obiettivi più ambiziosi messi a fuoco finora da Bruxelles: creare il primo impianto normativo al mondo sui sistemi IA. Ma i paletti piantati dall’Unione europea saranno sufficienti a contenere la frenesia con cui la Silicon Valley sta investendo nell’intelligenza artificiale? Ne parliamo con Guido Scorza, avvocato e membro del Garante per la Privacy.
Come e quanto ci riguardano le nuove regole concordate a Bruxelles? 
«Per saperlo con certezza dobbiamo aspettare il testo definitivo, diciamo che di qui a 2 anni le disposizioni saranno direttamente applicabili nel nostro ordinamento, proprio come succede già con il Gdpr, il regolamento europeo sulla privacy. Con tutte le conseguenze – e gli obblighi– del caso». 
Chi controllerà che le nuove regole vengano rispettate? 
«È prevista la creazione di un “ufficio europeo” dedicato all’IA, che dovrebbe operare in concerto con le autorità nazionali, un elemento fondamentale per garantire l’uniformità della disciplina. L’auspicio adesso è che all’interno dei singoli Paesi questo compito venga affidato a un’autorità indipendente e non a un’agenzia governativa».
Perché? 
«Qualcuno potrebbe avere la tentazione di approfittare dell’intelligenza artificiale piuttosto che di governarla». 
Teme che l’IA possa essere usato in maniera impropria dalle istituzioni? 
«È uno dei punti che hanno ritardato il negoziato, l’uso che potrebbero fare i governi del riconoscimento biometrico come strumento di sorveglianza di massa. Un’autorità super partes garantirebbe una maggiore indipendenza e potrebbe intervenire per far rispettare anche al governo i paletti imposti dal nuovo regolamento». 
Come giudica questi paletti nel testo attuale? 
«Quello che ho letto finora punta verso un impianto robusto. C’è una regolamentazione dei modelli generativi che fino a poco fa rischiavano di essere relegati all’autodisciplina. Sono previsti anche strumenti per la trasparenza sui contenuti algoritmici. L’IA è stata divisa in livelli di rischio e c’è il divieto assoluto di usare alcuni di questi sistemi. E c’è anche un accordo sul web scraping, cioè la raccolta dati sul web da parte degli algoritmi». 
Voi come Garante avete lanciato un’indagine conoscitiva su questo tema proprio qualche giorno fa. 
«La tesi che sosteniamo è che i dati pubblicati sul web non debbano restare alla mercé di chiunque per addestrare gli algoritmi. Quindi chi pubblica quei dati dovrebbe adottare delle misure di sicurezza per proteggerli dal rischio che poi passi il clone di turno di OpenAi o di Google e faccia incetta di quei dati». 
Alcune delle norme contenute nell’AI Act non si sovrappongono con il Gdpr? 
«In alcuni casi sì. Diciamo che il Gdpr è un sottoinsieme che può essere applicato in tutti quegli ambiti in cui l’IA per funzionare ha bisogno dei dati personali degli utenti. Fuori da questo sottoinsieme c’è tanto di nuovo e inesplorato ancora da affrontare in tema di IA. E un regolamento da questo punto di vista è il migliore degli strumenti possibili per farlo».

