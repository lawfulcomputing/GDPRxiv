

Le sfide dell'intelligenza artificiale a scuola: "Grandi potenzialità, ma prima serve rendere studenti e docenti consapevoli"
Intervista a Guido Scorza, Componente del Garante per la protezione dei dati personali
(di Chiara Barison, Il Corriere della Sera-LOGIN, 7 novembre 2023)
In attesa degli «Stati generale della scuola digitale» che si terrano a Bergamo il 24 e il 25 novembre, l'avvocato e membro del Garante Privacy Guido Scorza spiega i rischi della didattica digitale integrata
Tra i temi che verranno affrontati nell'ottava edizione degli «Stati generali della scuola digitale», l'evento che si terrà a Bergamo il 24 e 25 novembre (qui per iscriversi, qui il programma completo), non può mancare l'intelligenza artificiale. Proclamata come strumento che consentirà la realizzazione di una didattica personalizzata, cucita addosso alle esigenze di ogni studente, e per questo veicolo di uguaglianza ed inclusione, non è esente da rischi. Soprattutto se si ha a che fare con individui minorenni, le cautele richiedono un livello di attenzione più alta. Lo spiega Guido Scorza, avvocato, docente di diritto delle nuove tecnologie e privacy e membro del Garante per la protezione dei dati personali: «Le cose da tenere ben presenti quando si parla di intelligenza artificiale nelle scuole sono la trasparenza e la garanzia dell’effettiva autodeterminazione di studenti e genitori, anche se la corsa al digitale è ormai avviata non significa che dobbiamo accettare qualsiasi cosa senza senso critico».
Didattica digitale significa ottimizzazione dei tempi, ma secondo Scorza la parola chiave è «esempio»: «Se abituiamo l’alunno a relazionarsi con le tecnologie sottovalutando rischi e opportunità rischiamo di crescere adulti che sottovalutano gli effetti perché non conoscono il funzionamento di ciò che utilizzano». In concreto, si tratta di fare formazione sia a docenti che a studenti prima di integrare gli strumenti digitali alla didattica affinché i ragazzi comprendano come vengono utilizzati i dati che cedono alle piattaforme. «Spiegare ai ragazzi come funzionano gli algoritmi non significa farne degli scienziati – continua Scorza – ma renderli consapevoli di come vengono utilizzati i loro dati in quanto utenti».
Spiegare è il presupposto necessario della comprensione che permette di vietare l’assuefazione a quelli che sono prodotti creati da privati. «Bisogna intervenire prima che l’effetto seduttivo delle nuove tecnologie renda vano ogni sforzo. È stato così con ChatGpt – ricorda – dopo tanti anni di lavoro nelle scuole non ho mai preso così tanti fischi come quando sono andato in un istituto romano poco dopo il blocco del chatbot di OpenAI». Se è vero che non si può accettare passivamente che gli studenti facciano svolgere i temi a un sistema di intelligenza artificiale generativa, è altrettanto vero che un successo così diffuso e immediato pone l’accento su alcune riflessioni. «L’AI andrebbe usata dopo aver ripensato i processi di apprendimento: imporre di fare un tema può essere superato, allora perché non far analizzare un testo composto da un chatbot per trovare errori e inesattezze? Questi linguaggi fanno leva sulla nostra pigrizia di esseri umani, l’unico modo per gestirli è utilizzarli in modo attivo».
Dalla consapevolezza passa la libertà di scelta. Sul punto Scorza non ha dubbi: «Non dobbiamo trasformare le classi “digitali” in “greggi digitali” - aggiunge Scorza – è necessario tutelare le famiglie che decidono, ad esempio, di non acconsentire alla pubblicazione delle foto della gita scolastica».

