

Tutte le sfide della Privacy che ci attendono nel 2024
Intervento di Guido Scorza, componente del Garante per la protezione dei dati personali
(StartupItalia, 16 gennaio 2024)
Mai sin qui, nella storia dell’umanità i dati – a cominciare da quelli personali – erano stati tanto centrali per le cose dei mercati, della società e delle democrazie. I dati sono protagonisti del modello di business dell’intero ecosistema digitale o di buona parte di esso, sono protagonisti della dieta degli algoritmi di intelligenza artificiale che, in difetto, sarebbero bambini ineducati e inesperti e sono una delle migliori speranze per il mondo intero di fare rotta verso un futuro migliore che si parli di medicina e ricerca, di economia e finanza, di trasparenza e democrazia. Il 2024 non si sottrarrà a questa regola e, seppur con tutti i limiti di una società nella quale l’unica cosa prevedibile è che il futuro è imprevedibile, non è difficile immaginare che le regole sulla privacy avranno un impatto determinante nelle vite delle persone, della società nella quale viviamo, dei mercati e delle nostre democrazie. Più difficile provare a azzardare previsioni sulle questioni, tra le tante già sul tavolo, che terranno banco nei mesi a venire, a proposito di privacy e dintorni.
Il 2023 si è chiuso offrendoci alcuni indizi. Tanto per cominciare, proprio mentre i più di noi erano già alle prese con l’albero di Natale, Meta ha annunciato a centinaia di milioni di utenti europei che per continuare a usare i propri servizi avrebbero dovuto scegliere: abbonarsi e pagare un canone mensile o prestare il consenso all’utilizzo della profilazione per la diffusione di messaggi pubblicitari personalizzati. “Pay or ok”, insomma. Lo stesso modello di business già utilizzato, in giro per l’Europa, da diversi editori di giornali online. Lecito o illecito? Una risposta è, evidentemente, urgente e difficilmente si potrà fare a meno di individuarla già nei primi mesi del 2024. Se si dice di si, il rischio, è che il diritto alla privacy diventi un diritto per soli ricchi perché, naturalmente, a questi ultima costa di meno dire di no a che i propri dati personali siano trattati per finalità pubblicitarie e accettare di pagare qualche euro al mese. E, però, la privacy è un diritto fondamentale che dovrebbe essere universale ovvero garantito allo stesso modo a tutti, a prescindere, tra l’altro, da ceto sociale e conto in banca. Se si dice di no, si rischia di andare contro la storia che ha fatto di questo “scambio”, dati contro servizi, il modello di business di buona parte dell’ecosistema digitale ma, soprattutto, si rischia di stabilire un principio non facile poi da far rispettare e, quindi, incapace di garantire effettivamente alle persone quei diritti e quelle libertà che, affermandolo, si vorrebbe loro garantire. Ma soprattutto mentre l’inalienabilità dei diritti fondamentali è un elemento certo, l’indisponibilità di quantità date di dati personali e di singole forme di esercizio del diritto è meno scontata. D’altra parte, sin qui le Autorità di protezione dei dati personali in giro per l’Europa hanno dato risposte diverse alla questione. Ora, però, serve risolverla all’unisono per garantire alle persone e all’industria un’adeguata certezza del diritto.
Quello appena iniziato sarà anche, come d’altra parte accaduto per l’anno appena finito, l’anno dell’intelligenza artificiale e, in particolare, della sua definitiva affermazione come fenomeno di massa. È facile prevedere che al crocevia tra privacy e intelligenza artificiale ci sarà fermento, ci saranno novità, discussioni accese e probabilmente scontri. Tante, al riguardo, le questioni sul tavolo ma una svetta per importanza e per urgenza ed è quella relativa all’addestramento degli algoritmi.
È lecito o no pescare a strascico da internet miliardi di dati personali riconducibili a miliardi di persone per addestrare algoritmi di intelligenza artificiale come accaduto sin qui? Anche qui non è facile né correre a rispondere di si, né affrettarsi a dire di no. Nel primo caso si accetterebbe l’idea che dati personali rappresentativi di un diritto fondamentale possano essere trasformati in asset commerciali e tecnologici di una manciata di società commerciali senza che gli interessati – ovvero le persone alle quali i dati in questione si riferiscono – abbiano mai autorizzato un simile sfruttamento. È uno scenario giuridicamente legittimo e democraticamente sostenibile? Se si risponde di no, d’altra parte, si mette un’ipoteca non di poco conto sul futuro dell’intelligenza artificiale perché, allo stato, non è scontato che esistano soluzioni diverse per addestrare almeno certi tipi di algoritmi. Certo soluzioni intermedie sono sempre possibili ma non sono facili da immaginare e, soprattutto, da implementare. Però una soluzione va trovata. In Italia c’è un’istruttoria – quella nei confronti di OpenAI per il servizio ChatGPT3 – la cui definizione presuppone inesorabilmente l’identificazione di questa soluzione. In Europa d’altra parte è al lavoro la task force costituita in seno all’EDPB, proprio per cercare di arrivare a una posizione comune.
Due questioni epocali e che, pure, difficilmente ci si potrà sottrarre dall’affrontare e provare a risolvere nei prossimi mesi mentre, peraltro, tante altre faranno capolino e altre ancora si imporranno all’attenzione di stakeholders pubblici e privati come ancora più urgenti. Chi segue le cose dei dati personali e della privacy, per certo, nel 2024, non si annoierà.

