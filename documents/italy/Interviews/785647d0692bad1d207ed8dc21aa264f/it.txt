


Ragazzini che spogliano ragazzine con l'intelligenza artificiale: un fenomeno da fermare subito
Ragazzini che spogliano ragazzine con l'intelligenza artificiale: un fenomeno da fermare subito
Ormai basta una foto del viso della vittima, una qualsiasi, qualche minuto di pazienza, l’app giusta e il gioco – che non è un gioco ma un gesto di efferata violenza – è fatto. Per porre rimedio, ci sono due leve che è urgente azionare
Intervento di Guido Scorza, componente del Garante per la protezione dei dati personali
(HuffPost, novembre 2023)
Le storie, purtroppo, rimbalzano a ritmo crescente dalla Spagna all’Italia e dall’Italia agli Stati Uniti e si moltiplicano alla velocità della luce: ragazzini che “spogliano” ragazzine grazie ad applicazioni di intelligenza artificiale sempre più facili da usare e poi condividono le foto in questione attraverso le app di messaggistica, i social network e i siti pornografici. Ormai basta una foto del viso della vittima, una qualsiasi, qualche minuto di pazienza, l’app giusta e il gioco – che non è un gioco ma un gesto di efferata violenza – è fatto.
Un istante dopo per le vittime inizia un dramma del quale, nella più parte dei casi, i carnefici digitali in erba non arrivano a percepire l’entità e le diverse possibili conseguenze.
Solo nelle ultime settimane è accaduto nella cittadina spagnola di Almendralejo, è accaduto in Italia a Treviso e, da ultimo, negli Stati Uniti in New Jersey o, meglio, sarà certamente accaduto ovunque ma queste sono alcune delle storie rimbalzate sui media. Ma le proporzioni del fenomeno sono letteralmente devastanti e, soprattutto, il trend registra una crescita esponenziale.
Secondo una ricerca indipendente recentemente pubblicata negli Usa da Wired, nei primi nove mesi del 2023 il numero di video falsi artificialmente modificati pubblicati sulle 35 piattaforme specializzate nella condivisione di questo genere di contenuti è cresciuto del 54% rispetto all’anno precedente.
Alla base dell’impennata c’è la diffusione dei servizi di intelligenza artificiale che consentono la produzione dei fake e, soprattutto, la crescente semplicità d’impiego.
Inutile dire che, specie se la vittima è un’adolescente – ma le considerazioni non sono diverse per le vittime adulte – il rischio che la diffusione di un video del genere le distrugga irreparabilmente la vita è enorme.
E inutile soprattutto girarci attorno: siamo davanti a episodi di violenza sessuali che non meritano di essere considerati meno gravi rispetto a quelli di violenza fisica e che, in ogni caso, integrano il reato di diffusione di immagini pedopornografiche, ogni qualvolta la vittima è una minore.
Ma il punto, nella situazione in cui siamo, non sono e non possono essere le regole che ci sono e che possono, naturalmente, essere sempre migliorate, il punto è che mentre il mondo intero è impegnato a discutere di queste nuove regole, mentre ogni giorno si annuncia la nascita di una nuova commissione, mentre si moltiplicano – per ragioni più o meno nobili – i progetti di governo del fenomeno, centinaia – o forse migliaia – di bambine e bambini ogni giorno vengono esposti a rischi drammatici e insostenibili.
Bisogna intervenire e bisogna farlo subito.
E, purtroppo, le iniziative regolamentari appena introdotte nel nostro Ordinamento in sede di conversione in legge del c.d. Decreto Caivano – gli strumenti di parental control sugli smartphone e l’age verification per l’accesso alle piattaforme pornografiche – non sembrano destinate a avere alcun impatto sul fenomeno.
Ci sono due leve che è urgente azionare.
La prima riguarda l’integrazione in tutte le piattaforme attraverso le quali i contenuti in questione vengono normalmente diffusi – le app di messaggistica, i social network, i siti di condivisione di contenuti audiovisivi – di soluzioni tecnologiche, ormai esistenti e affidabili che consentono di identificare i contenuti “taroccati” artificialmente e di segnalare tale circostanza agli utenti. Che almeno si sappia che il video che si ha davanti e che ritrae la compagna di scuola nuda e/o impegnata in chissà quali gesta erotiche è o potrebbe essere falso non è la soluzione del problema ma può mitigarne le conseguenze.
La seconda riguarda l’accessibilità di questi strumenti di manipolazione digitale diversamente intelligenti – perché qui l’espressione “intelligenza artificiale” si rivela davvero inappropriata – da parte di un pubblico minorenne: va semplicemente esclusa senza starci a pensare due volte. I fornitori di questo genere di soluzioni vanno obbligati a dotarsi di strumenti di age verification efficaci e se non lo fanno accompagnati fuori dal mercato. Ma questo non quando disporremo, tra qualche anno, delle nuove regole europee sull’intelligenza artificiale nel pieno del loro vigore ma oggi. E non è questione di aver paura dell’intelligenza artificiale ma semplicemente di essere consapevoli che la più utile e preziosa delle tecnologie nelle mani di chi non è in grado di comprenderne le potenzialità e percepire i rischi connessi al suo utilizzo può diventare un’arma letale. È, in fondo, lo stesso principio per il quale non lasciamo che un bambino guidi un motorino o un’automobile: il problema non è la pericolosità dei messi in sé ma la loro pericolosità nelle mani di ch  non ne conosce e non ne può, normalmente, conoscere le regole e le dinamiche di funzionamento.

