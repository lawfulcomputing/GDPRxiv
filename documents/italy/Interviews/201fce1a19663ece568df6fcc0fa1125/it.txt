

L'Authority Usa striglia le fabbriche degli algoritmi
Intervento di Guido Scorza, componente del Garante per la protezione dei dati personali
(AgendaDigitale, 10 gennaio 2024)
In un comunicato pubblicato sul proprio sito istituzionale lo scorso 9 gennaio la Federal Trade Commission, l’Autorità che negli Stati Uniti d’America è tra l’altro responsabile di proteggere la privacy, i mercati e i consumatori lancia un monito durissimo alle fabbriche degli algoritmi a stelle e strisce. “Non esiste nessuna deroga per chi produce intelligenza artificiale rispetto alle regole del gioco, a cominciare da quelle in materia di privacy, trasparenza e concorrenza”, scrive la FTC.
I dati, a cominciare da quelli personali, giocano un ruolo centrale nell’industria e nel mercato dell’intelligenza artificiale ma tale centralità deve essere ragione per preoccuparsi, eventualmente di più ma non certamente di meno dell’importanza di rispettare le leggi.
In particolare, la preoccupazione alla quale il comunicato dell’Autorità americana da voce riguarda il rischio che per addestrare gli algoritmi le società specializzate in AI sfruttino, tra gli altri, i dati personali di utenti di servizi forniti da terze parti ma basati sulle intelligenze artificiali in questione senza darne alcuna evidenzia a questi ultimi o, comunque, senza disporre di una valida base giuridica per procedere in questo senso.
Questa volta non sono le Autorità europee a richiamare all’ordine l’industria americana dell’intelligenza artificiale, quindi, ma la severissima e temutissima Federal Trade Commission. Insomma non è più l’Europa della privacy e dei diritti fondamentali contro l’America dei mercati e dell’innovazione.
Le preoccupazioni, da una parte e dall’altra dell’oceano sono condivise, forse a conferma che la situazione attuale inizia a apparire universalmente insostenibile e che non c’è più regolatore o decisore pubblico al mondo che non avverta forte un senso di preoccupazione per quanto sta accadendo. E in effetti la situazione è sempre meno sostenibile sia in termini giuridici che democratici.
Il quadro, riassunto ai termini essenziali, è questo: i diritti fondamentali, a cominciare da quello alla privacy (ma il diritto d’autore non conta di meno) di miliardi di persone vengono pescati a strascico e sfruttatati massivamente da una decina di corporation e, per questa via, trasformati in asset commerciali e tecnologici da valorizzare sui mercati globali e, come se non bastasse, poi sfruttati per sottrarre opportunità di business ai tanti che quei dati, quelle informazioni e quei contenuti hanno prodotto o generato o, comunque, ai quali i dati personali appartengono. Ma il comunicato della Federal Trade Commission è importante soprattutto per l’avvertimento che lancia all’indirizzo di chi, sin qui, avesse trattato illecitamente dati personali per addestrare i propri algoritmi.
La conseguenza, infatti, secondo l’Autorità americana potrebbe non essere solo di tipo sanzionatorio ma potrebbe spingersi sino a un ordine di cancellazione di tutti i dati sin qui raccolti e, soprattutto, di inutilizzabilità assoluta dei modelli di intelligenza artificiale sviluppati grazie al trattamento eventualmente illecito di dati personali.
È una conseguenza astrattamente capace di riportare le lancette dell’orologio dell’industria mondiale dell'intelligenza artificiale, indietro di diversi anni, davanti alla quale il provvedimento di sospensione temporanea del trattamento dei dati personali a suo tempo impartito dal Garante italiano per la privacy, all’indirizzo di OpenAi, impallidisce.
Tra tante incertezze, c’è una sola certezza che esce rafforzata dal comunicato della FTC: l’industria e il mercato dell’AI sono straordinariamente fragili perché le loro fondamenta, rappresentate dall’addestramento degli algoritmi, sono basate su presupposti giuridici ancora mai validati nella loro tenuta né in Europa, né negli USA, con la conseguenza che l’intero impianto potrebbe franare da un momento all’altro.
Mettere ordine nelle regole e chiarire le regole del gioco così da poter contare su un’adeguata misura di certezza del diritto, a questo punto della partita, dovrebbe essere una priorità per tutti.
 

