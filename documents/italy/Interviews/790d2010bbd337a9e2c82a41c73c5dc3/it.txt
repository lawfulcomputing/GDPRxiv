

Scorza: “Dati pescati a strascico dall’intelligenza artificiale, perché la nostra indagine”
Intervento di Guido Scorza, componente del Garante per la protezione dei dati personali
(AgendaDigitale, 23 novembre 2023)
I dati personali di miliardi di persone, frammenti della loro identità personale e “titoli rappresentativi” di un diritto fondamentale come il diritto alla privacy vengono letteralmente pescati a strascico dalle grandi fabbriche dell’intelligenza artificiale globale per l’addestramento dei propri algoritmi e, dunque, trasformati in assets commerciali e tecnologici di pochi al fine consentire a questi ultimi di fare business.
Il tutto avviene come se il web fosse un’immensa prateria nella quale tutto è di tutti e chiunque può pertanto impossessarsene e farlo proprio per qualsiasi finalità.
Il problema del cambio finalità
Ma, forse, questa immagine è, almeno, inesatta.
I dati personali che i crawler delle big tech dell’intelligenza artificiale raccolgono online, infatti, sono pubblicati da una pluralità di soggetti – i gestori dei siti internet – per una serie di finalità necessariamente predeterminate e diverse dall’addestramento degli algoritmi: il diritto di cronaca nel caso degli editori, la trasparenza nel caso delle pubbliche amministrazioni, un contratto con gli interessati nel caso di siti destinati alla pubblicazione di ogni tipo di annunci da quelli commerciali a quelli personali e sentimentali ecc.
Ed è proprio qui che nasce il dubbio che con un’indagine conoscitiva appena avviata, come Garante per la protezione dei dati personali, vorremmo approfondire e attorno al quale vorremmo avviare una riflessione ampia e condivisa: i gestori dei singoli siti internet che costituiscono i “pascoli” attraverso i quali gli algoritmi delle major dell’intelligenza artificiale sono sfamati dovrebbero o non dovrebbero proteggere i propri confini con idonee misure di sicurezza capaci di impedire a terzi di appropriarsi di ciò che loro pubblicano per una finalità determinata?
E in caso di risposta affermativa quale potrebbe essere una soglia ragionevole per un simile obbligo?
Potrebbe, ad esempio, trattarsi dell’adozione, almeno, degli strumenti che, proprio a tal fine – anche se, in realtà, sulla base di preoccupazioni relative prevalentemente al diritto d’autore e alla concorrenza sleale – le grandi fabbriche degli algoritmi o, almeno, alcune di esse già rendono disponibili e che, alcuni editori – si veda ad esempio il caso del New York Times – hanno già annunciato di aver implementato?
Ovviamente non è l’unica risposta possibile.
Guai a dirsi certi di questa o quella soluzione perché la materia è complessa ma la questione sembra meritare più attenzione di quanta, sin qui, in giro per il mondo, sembra averne ricevuta.
Strumenti di sicurezza contro web scraping
Ma al titolare del trattamento che trattando i dati personali per una certa finalità non si curi di adottare idonee misure di sicurezza che proteggano tali dati da eventuali utilizzi diversi, anche da parte di terzi, normalmente si contesta l’inadempimento alla disciplina europea proprio per non essersi preoccupato di difendere dati che non diventano mai “suoi” ma in relazione ai quali ha, al massimo, un diritto di utilizzazione per una certa finalità.
Certo le misure in questione, che si pensi a quelle dell’articolo 25 o a quelle dell’articolo 32 devono essere sempre proporzionate.
Ci sono misure nel caso di specie che potrebbero essere considerate tali?
Viene da pensare di sì a guardare alla facilità con la quale almeno gli strumenti messi a disposizione dei gestori dei siti internet da alcuni dei giganti dell’AI possono essere implementati sui siti internet.
È un esercizio che non sembra più complesso di quello necessario, attraverso comandi analoghi, a garantire che il contenuto di una pagina web venga sottratto all’indicizzazione, ad esempio per ragioni connesse al diritto all’oblio, quindi un esercizio apparentemente accessibile, al quale gli addetti ai lavori, almeno nel metodo, sono abituati da tempo memorabile.
Ma anche a questo potrebbe servire l’indagine conoscitiva.
L’esigenza di capire se e cosa si può fare
Nessuna certezza, nessun provvedimento, nessuna decisione definitiva ma l’esigenza di capire se e cosa si può fare – a prescindere dal continuare a chiederci, a livello nazionale e europeo, se e quale possa essere la base giuridica che legittima una fabbrica di algoritmi a trattare i dati personali di miliardi di persone per addestrarli, senza chiedere alcun consenso – per fare in modo che l’inarrestabile e prezioso sviluppo delle intelligenze artificiali avvenga senza travolgere completamente i diritti dei singoli e, naturalmente, in particolare, il diritto alla privacy.
Ai fini dell’indagine che si concluderà sessanta giorni dopo il suo lancio saranno importanti i contributi che potranno essere trasmessi dalle associazioni di categoria interessate, dalle associazioni di consumatori, da esperti e rappresentanti del mondo accademico.
Il primo obiettivo, insomma, è capire.
Prossimo passo: valutare provvedimenti
Poi, una volta chiusa l’indagine, si procederà alle valutazioni del caso e ove si ritenesse ne sussistano i presupposti, si valuterà se e quali provvedimenti adottare per garantire che, eventuali obblighi rinvenibili in capo ai gestori dei siti internet, titolari del trattamento siano effettivamente adempiuti.
Da qui a lì, tuttavia, l’avvio dell’indagine conoscitiva vale, probabilmente, comunque a richiamare l’attenzione di tutti i titolari del trattamento interessati sull’opportunità, in una logica di accountability e in termini di privacy by design e by default, di porsi il problema e affrontarlo come, peraltro, ha di recente fatto qualche editore in giro per il mondo sebbene a difesa dei propri diritti d’autore.
Perché mai il diritto alla privacy di miliardi di persone dovrebbe valere meno del diritto d’autore?
Sono due diritti fondamentali entrambi meritevoli di essere protetti, difesi e gestiti nel modo migliore possibile allo stato della tecnica.

