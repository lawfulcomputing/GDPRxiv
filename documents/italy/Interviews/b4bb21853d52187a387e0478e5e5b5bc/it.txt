

Con l'Al Act le regole inseguono la tecnologia: sarà così anche per l'America?
Intervento di Guido Scorza, componente del Garante per la protezione dei dati personali
(MF, 31 ottobre 2023)
La regolamentazione insegue da sempre il progresso e l'innovazione tecnologica e, quindi, non c'è da stupirsi che questo stia accadendo anche a proposito dell'iniclligenza artificiale. In questo caso, tuttavia, lo sviluppo tecnologico e l'impatfo dell'intelligenza artificiale sulla società ha un vantaggio maggiore di sempre sulla regolamentazione. Basta guardare alla vicenda del draft di regolamento europeo sull'intelligenza artificiale (l'AI Act che dovrebbe entrare in vigore la prossima estate e di cui ha parlato Milano Finanza di sabato) e soprattutto all'atto esecutivo del presidente Biden a tutela della privacy dei cittadini degli Stati Uniti: i governi stanno prendendo le misure a questa nuova rivoluzione digitale, ma con quale velocità? Il regolamento europeo, l'AI Act, avrà un percorso lungo con possibili modifiche entro la fine dell'anno. Ma poi, una volta approvato definitivamente, sarà inevitabile dare ai Paesi membri un termine, difficilmente inferiore all'anno e, anzi, forse, superiore, per prepararsi a dare diretta applicazione alle sue regole. Difficilmente insomma le nuove regole saranno legge per davvero prima del 2025.
E naturalmente lo sviluppo dell'intelligenza artificiale e la sua diffusione sui mercati globali non si fermerà in attesa di questa data con due conseguenze non di poco conto. La prima è che, inesorabilmente. le nuove regole, quando entreranno in vigore, non saranno in grado di governare applicazioni diversamente intelligenti che oggi non sono ancora emerse o, semplicemente, che oggi non appaiono ancora meritevoli di uno specifico intervento normativo. In fondo è esattamente quanto già accaduto per le intelligenze artificiali generative - quelle alla Chat Gpt per intenderci - che non erano state originariamente considerate nell'originaria proposta dell'AI Act e delle quali, quindi, ci si è provati ad occupare in corsa quando il testo era già entrato nel rettilineo finale. Non è colpa di nessuno ma è, semplicemente, una conseguenza del disallineamento temporale prepotente tra i ritmi della produzione regolamentare - anche quando si preme il piede sull'acceleratore il più possibile come è staio indiscutibilmente fatto nel caso dei lavori preparatori dell'AI Act e quelli dello sviluppo tecnologico. Eppure il problema esiste,
La seconda è rappresentata dall'esigenza di trovare un modo di governare l'intelligenza artificiale nei prossimi mesi, nel prossimo anno o, forse, di più. Perché, in difetto, rischio è che la tecnologia si faccia essa stessa regolamentazione e finisca con il plasmare le nostre vite, nella dimensione personale e in quella professionale, in quella individuale e in quella aggregata, nel contesto pubblico e in queÌÌo privato in maniera persino più stringente di quanto non facciano generalmente le regole che escono dai nostri Parlamenti e governi. In fondo è già largamente successo con Internet, La più parte dei nostri comportamenti quotidiani nella dimensione digitale è tecno-governata: li poniamo in essere o non li poniamo in essere perché le tecnologie che usiamo ce li consentono o ce li impediscono più che perche lo facciano le leggi. E questo è un problema enorme. Le regole imposte a mezzo tecnologia, infatti, nascono nei laboratori tecnologici e/o negli studi legali di una manciata di società commerciali e sono, dunque, adottate - peraltro legittimamente fino a prova contrario - nel nome di interessi privati mentre le regole che escono dai nostri Parlamenti e dai nostri governi sono adottate - o, almeno, dovrebbero essere adottate - in nome dell'interesse pubblico.
E la distanza che c'è tra la tecnocrazia e la democrazia e non si può lasciare che la seconda sia travolta dalla prima. Ma il rischio è quanto mai attuale. Per scongiurarlo l'Unione Europea, consapevole che nel caso dell'impatto dell'intelligenza artificiale sulla società non si può attendere il 2025 per provare a oriéntame lo sviluppo e l'uso in una direzione sostenibile, sta proponendo ai giganti tecnologici dell'intelligenza artificiale di impegnarsi, su base volontaria, a rispettare le regole che saranno contenute nell'Ai Act una volta approvato prima che scada il termine per la sua diretta applicabilità nei diversi Paesi membri. Insomma, una sorta di pre-applicazione volontaria di indicazioni che domani saranno obbli gatorie,
L'esercizio si chiama AI Pact. L'idea è buona e mostra consapevolezza del problema da parte delle Istituzioni euro-unitarie. Che sia anche efficace è, però, tutto da vedere. Vedremo innanzitutto se e quanti tra i protagonisti globali della corsa all'intelligenza artificiale vi aderiranno, Ma anche chi dovesse aderire avrà bisogno di tempo per mettersi in riga. Senza dire che la vigilanza, in un esercizio tutto su base volontaria, sarà blanda se non inesistente: e, d'altra parte, la più parte dei Paesi dell'Unione non ha ancora identificato l'Autorità che sarà chiamata a vigilare sull'AI Act che, di conseguenza, non potrà vigilare sul rispetto del AI Pact. E allora?
L'importante è non porsi in messianica attesa delle nuove regole e non scommettere tutto sulla loro applicazione volontaria da parte dei protagonisti dei mercati perchè non si parte da zero e potremmo scoprire che le regole che ci sono, pur non essendo state pensate per l'AI, possono consentirci di in maniera efficace. Per il futuro, Al a parte, bisogna però ripensare al modo in cui si governa rinnovazione tecnologica: servono meno regole più di alto livello, approvate in tempi più serrati e volte poi a delegare a valle la regolamentazione di dettaglio, magari a autorità amministrative indipendenti capaci di passare dal pensiero all'azione in qualche mese perché, altrimenti, il rischio di ritrovarci con le nostre democrazie travolte dalla tecnocrazia diventerà insostenibile.

