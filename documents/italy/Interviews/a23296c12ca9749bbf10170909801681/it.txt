

AI e diritto: “L’umanesimo digitale diventa concreto solo con le regole”
Parla Ginevra Cerrina Feroni vicepresidente dell’autorità Privacy
Dall'intervento di Ginevra Cerrina Feroni, Vice Presidente del Garante per la protezione dei dati personali, al convegno “Intelligenza artificiale e decisioni automatizzate”, 22 gennaio 2024, Università di Firenze
(www.thedotcultura.it, 24 gennaio 2024)
Intelligenza Artificiale e quadro giuridico, ovvero; è possibile regolamentare a livello giuridico uno dei fenomeni che a buon diritto si possono definire epocali, per qualcuno destinato a cambiare per sempre la storia dell’umanità? Risposta non semplice eppure necessaria, come è emerso dal convegno che si è tenuto ieri, 22 gennaio, “Intelligenza artificiale e decisioni automatizzate”, presso la sede dell’Università di Firenze. Il quadro della giornata lo fornisce il professor Erik Longo, organizzatore nonché moderatore della prima sessione della mattinata. L’iniziativa si è svolta nell’Aula Magna del Rettorato, a Firenze, in piazza San Marco.
Il professor Longo, che è anche responsabile del progetto dell’Università di Firenze ARC II che si occupa dei problemi della compliance relativi al GDPR (acroni1mo di General Data Protection Regulation,) da parte soprattutto delle piccole e medie imprese, traccia il quadro generale della situazione: “La riflessione parte dal tema delle decisioni automatizzate e in particolare nel ruolo che svolge l’AI nell’assistenza alle nostre azioni quotidiane, a partire dal lavoro, alle attività delle Pubbliche Amministrazioni e nelle imprese. L’Intelligenza Artificiale è oggi una delle parole chiave della contemporaneità. siamo consapevoli che esistono molti benefici, ma anche molti rischi”. Ed è questo il tema fondante dell’incontro: si possono limitare i rischi? E come? In prima istanza, come spiega Longo, è senz’altro indispensabile la consapevolezza nell’uso e nell’approccio a queste macchine; ma allo stesso tempo, è necessario “un ecosistema di regole efficaci ed effettive al tempo stesso”.
Regole che sostanzialmente hanno di mira la tutela di uno dei beni più, di fatto, evanescenti dal punto di vista digitale, della contemporaneità, ovvero il diritto alla privacy. Un tema esploso grazie al contributo del Garante italiano, come ricorda la vicepresidente Ginevra Cerrina Feroni: “Siamo intanto in attesa dell’entrata in vigore del nuovo regolamento europeo dell’intelligenza artificiale che introduce una serie di coordinati di grandissimo rilievo, distinguendo trattamenti vietati, che sono assolutamente contrari perché violano libertà e diritti fondamentali, trattamenti ad alto e medio rischio e trattamenti ammessi. Questo regolamento tuttavia non è ancora entrato in vigore, per cui si applica la normativa sulla protezione dei dati personali, che è ciò che da anni applica il Garante. Quindi, ancora prima del regolamento che uscirà, già esistono le norme, dal momento che i trattamenti automatizzati devono, con intelligenze artificiali e algoritmi, rispondere a determinati requisiti”. E anche a delle domande: i dati che vengono raccolti chi li conserva? Come vengono trattati? Per quanto tempo vengono conservati? Con chi vengono condivisi? Quali sono i diritti dei cittadini rispetto alla proprietà?.
Domande che potrebbero replicarsi per quasi ogni applicazione dell’AI, e che fa comprendere come mai da tema sconosciuto ai più, da qualche mese sia esploso, forse anche grazie al contributo che ha dato sul tema il Garante italiano. “Chapt Gpt esce sul mercato italiano nel novembre 2022 – ricorda Cerrina Feroni nel suo intervento -le sue potenzialità sono subito evidentemente enormi. come i rischi. L’intervento del Garante, prima autorità al mondo ad intervenire con un provvedimento di limitazione provvisoria, in attesa dei primi chiarimenti sulla tenuta del sistema rispetto ai principi del regolamento europeo. Quel provvedimento apre un dibattito, che fuoriesce immediatamente dai confini nazionali. Dibattito che vede subito un’assoluta dominanza dei critici, entusiasti della tecnologia che, si diceva, non si può fermare e qualsiasi intervento regolatorio viene bollato come antistorico”.
Tuttavia, a distanza di pochissimo, si comincia a levare qualche voce critica, si insinua qualche dubbio, sollecitato intanto dai ” primi output delle interrogazioni mosse a ChaptGpt, risposte del tutto fantasiose ed errate, che possono creare anche seri danni alla reputazione delle persone, ma emerge anche il “tema dei copyright, la perdita dei posti di lavoro nell’azienda Hollywood, le proteste dei sceneggiatori”, e così via. Le autorità europee si rivolgono al Garante italiano chiedendo chiarimenti e aprono la task force a livello europeo che sta lavorando, si cominciano le istruttorie negli USA (New York times) , e il resto è storia. Il grande tema che l’Italia mette sul tavolo è dunque la regolazione dell’impatto enorme che l’AI produce in tutti campi del sistema che potremmo definire tradizionale.
Regolazione giuridica o etica, la prima grande domanda. “Ho qualche perplessità sulla preponderanza del tema etico nell’approccio al concetto di intelligenza artificiale- dice la vicepresidente – perché credo diventi molto comodo nascondersi dietro standard etici che piacciono molto alle grandi aziende, la soft law, i codici di condotta che possono diventare tutto e nulla, anche alibi per continuare a fare business senza responsabilità. E’ molto meno comodo ragionare di regole giuridiche che si portano dietro delle sanzioni. Occorre quindi il diritto parametrato a quelli che sono i cardini dei sistemi democratici, cuore del costituzionalismo, separazione dei poteri, diritti e libertà fondamentali. Queste sono le nostre stelle polari e i nostri sentieri, perché l’AI ha a che fare esattamente con ciò, con i cardini di un sistema democratico. Il ruolo delle autorità è esattamente questo, tutela dei diritti degli individui che possono essere messi a rischio da sistemi di intelligenza artificiale non governati”.
“L’uomo al centro, l’umanesimo digitale, sono parole importanti – spiega Cerrina Feroni – parole che hanno bisogno però di essere declinate in termini concreti, altrimenti restano etichette. Non è retorica la definizione di “uomo al centro”, quella che è stata l’attività dell’autorità Privacy in questi anni, su questo tema dell’AI. E’ la prospettiva che si ricava dalla giurisprudenza del Garante in questi anni”. Un’attività che ha cominciato a muoversi ancora prima che entrasse in vigore il Regolamento europeo Protezione dei dati personali”.
Alcuni casi particolarmente interessanti rivelano l’impatto dell’AI in particolare generativa nel nostro mondo. Casi che “hanno permesso di tracciare indirizzi su questo grande tema. C’è già una giurisprudenza, sia per il settore pubblico che per quello privato. Il grande tema del settore pubblico è quello dell’evasione fiscale. Già intorno al 2013, abbiamo sistemi automatizzati capaci di processare grandissimi volumi di dati. E’ del 2013 la decisione del Garante circa il Redditometro, uno strumento automatizzato che serviva per analizzare i dati personali contenuti nell’anagrafe tributaria, ovvero per individuare quei contribuenti da sottoporre ad accertamento per rideterminarne il reddito reale. Era un sistema già molto avanzato di profilazione del contribuente che se risultava sospetto, poteva subire delle conseguenze. Il parere dell’Autorità fu favorevole, ma esprimendo una serie di paletti e garanzie per l’utilizzo dello strumento: trasparenza, contraddittorio, diritto di contestare la decisione dell’algoritmo”.
Sotto questo profilo, il Garante ha accompagnato i provvedimenti di ciascun governo, cercando di “contemperare lotta all’evasione fiscale con tutela dei contribuenti”. Ciò è avvenuto attraverso un dialogo continuo fra Agenzia delle Entrate e Garante (insediatosi nel 2019), per giungere all’utilizzo di strumenti conformi al contemperamento fra necessità di lotta all’evasione e necessità di protezione dei dati personali. Altro tema enorme è la sanità, “dove l’impatto dell’AI è dirompente, la pandemia avendo funzionato come un acceleratore straordinario. Pochi settori hanno conosciuto una digitalizzazione così ingente ed attesa. Il Garante sta cercando di presidiare (i provvedimenti sono tantissimi) la funzione di provvedimenti anti covid che prevedevano l’uso di tecnologie con attività incessante di verifica e tutela dei diritti di libertà. ricordo l’app Immuni, che è stata forse uno dei più grandi strumenti di algoritmo di intelligenza artificiale per i tracciamenti, in cui l’autorità dette una serie di indicazioni alla società produttrice che vennero ottemperate. il sistema non funzionò, ma non per colpa della privacy, ma perché le Asl non furono in grado di gestire l’enorme mole di dati che vennero acquisiti”.
Non solo. L’AI ormai, come noto, viene utilizzata anche per prendere decisioni strategiche. “Nel 2020 – ricorda la vicepresidente – esprimemmo un parere per il Consiglio di Stato sulla ripartizione dei fondi dal fondo sanitario nazionale tra le regioni. Il governo voleva passare dal modello fondato sull’età della popolazione a uno basato sull’effettivo bisogno economico del territorio. Ma la transizione al nuovo modello necessitava di una profilazione dello stato di salute di ogni singolo assistito del SSN, permettendo al Ministero di rendere interoperabili molte delle banche dati pubbliche per tracciare il profilo sanitario individuale di ciascun utente, per collegarlo poi al suo reddito, allo status sociale. Non era cosa da poco”. Il parere del Garante fu negativo, dal momento che “si ritenne che mancasse una base giuridica per raggiungere i principi fondamentali, conoscibilità dei processi decisionali automatizzati, non esclusività della decisione algoritmica, non discriminazione algoritmica”. Principi che ad oggi sono confluiti in un decalogo elaborato dal Garante. Due casi emblematici, che tornano nella ratio di altri settori, dal sociale (ad esempio come si erogano sussidi, sovvenzioni, ecc) fino al tema molto delicato della Pubblica Sicurezza, fra cui il tema del riconoscimento facciale per pubblica sicurezza, è uno degli usi “più critici del sistema di intelligenza artificiale, oggetto di una grande discussione anche a livello europeo.
”Abbiamo adottato un provvedimento molto significativo, di fatto un parere negativo sul cosiddetto sistema SARI-Real time. E’ un sistema che avrebbe potuto consentire, tramite registrazioni di video camere, l’analisi dei volti dei cittadini confrontandoli in tempo reale con una banca dati di 10mila ritratti, per attuare un riconoscimento facciale con apposito algoritmo. Questo avrebbe creato un’alert per gli agenti. Il problema era che con questo grande sistema (di fatto di sorveglianza di massa) si andavano a intercettare anche persone che magari stavano in piazza per manifestare legittimamente, come ad esempio studenti in un corteo”.
Planando nell’ambito privato, un tema enorme, dal momento che da anni i privati stanno facendo un uso estesissimo di algoritmi -intelligenza artificiale, “ricordo il tema del lavoro, su cui posso dire che siamo orgogliosi dei provvedimenti adottati fra il 2020 e il 2021 nei confronti di Deliveroo Italia, ovvero nei confronti dei rider . La piattaforma trattava i dati personali di 8mila riders per l’assegnazione dei turni di lavoro, analizzando come i riders esercitavano il loro lavoro con un tracciamento ogni 12 secondi, con tutti i percorsi effettuati che venivano conservati per mesi. Trattamenti eccessivi, forse neppure giustificati rispetto allo scopo, nella totale inconsapevolezza dei riders stessi. L’algoritmo determinava delle discriminazioni su rider considerati meno affidabili, senza tuttavia tenere in conto le ragioni per cui a quella consegna non eri arrivato, perché magari avevi ricevuto una telefonata di emergenza dalla famiglia, oppure avevi avuto un malore, oppure hai avuto un incidente, come successe purtroppo a Firenze, un giovane rider licenziato dopo che era rimasto ucciso in un incidente”.
I temi sono moltissimi (basti pensare all’istruzione in tempi di covid) ma l’ultimo e forse il più inquietante è quello dell’intelligenza generativa, che non si ferma a ChaptGpt. “Abbiamo adottato provvedimenti importanti nei confronti di Clear View AI, un motore di ricerca che consente il riconoscimento facciale con tecniche di web scraping, dove sono state raccolte 10mila immagini, e quindi è possibile con semplici sistemi di matching andare a individuare le persone, con dati legati alla geolocalizzazione, alla data di nascita, ecc”. Atro passaggio importante, l’intervento del Garante su Replika, una chatboot che ha la capacità di creare persone virtuali, “l’amico del cuore, l’amico su misura, con rischi gravissimi nei confronti dei minori in particolare, i soggetti più fragili”. Infine, l’altro grande tema, quello della web reputation, anche se il Garante, come ricorda Cerrina Feroni, ha cercato di tamponare in questi anni le continue richieste di nascita di banche dati reputazionali.
“E’ molto difficile fare delle previsioni sulle prospettive future – conclude la vicepresidente del Garante Privacy – una tendenza emergente ad oggi è l’uso massiccio di tecniche di web scraping a cui ricorrono tutti i titolari di intelligenze artificiali per estrarre dati disponibili su web, con lo scopo di addestrare i propri algoritmi proprietari. Con implicazioni privacy molto serie, dalla proprietà intellettuale, fake, semplicemente la semplificazione per il lancio di attacchi informatici. Ciò che è certo, è che la distinzione fra dato personale e dato non personale diventa sempre più labile, poiché essendo più facile risalire all’identità della persona fisica, non si potrà prescindere dalla protezione dei dati personali, Non so valutare in concreto se all’autorità Privacy verranno riconosciuti dei ruoli formali di governance nazionale. Al momento, non mi pare che il dibattito, almeno italiano, proponga esiti chiari, mi pare tuttavia che un eventuale incardinamento completo della gestione AI in capo al governo, o direttamente o attraverso agenzie, possa presentare qualche profilo problematico”. L’intelligenza artificiale, come già sottolineato, “ha a che fare con la tenuta dei sistemi democratici”.

