

Audizione del Presidente del Garante per la protezione dei dati personali, Prof. Pasquale Stanzione - Indagine conoscitiva "Rapporto IA - Lavoro" 
Camera dei Deputati - XI Commissione (Lavoro)
(7 maggio 2024)
- IL VIDEO DELL'AUDIZIONE
Ringrazio anzitutto la Commissione per aver voluto includere, nell’ambito dell’indagine conoscitiva, anche il punto di vista della protezione dei dati: non scontato ma importante, tanto più rispetto alla congiunzione tra i.a. e lavoro.
Se, infatti, come si dirà, la protezione dei dati è una componente determinante della regolazione dell’i.a., il lavoro costituisce- non da ora -un contesto in cui i diritti di libertà, quali appunto quello alla privacy, assumono un ruolo rilevante. Stefano Rodotà notava come la privacy in Italia abbia avuto il suo primo riconoscimento con lo Statuto dei lavoratori e le sue norme tese a garantire la libertà di autodeterminazione del lavoratore rispetto a controlli datoriali suscettibili di raggiungere, anche grazie alla tecnologia, particolari livelli di invasività. Le garanzie in quest’ambito sono affidate agli strumenti del divieto, riferito a trattamenti di dati suscettibili di ledere in misura intollerabile l’autodeterminazione (art.8: divieto d’ indagine sulle opinioni, in particolare di politico-sindacali, dei lavoratori) e del limite, condizionato all’assolvimento di obblighi tra i quali quelli informativi (art. 4, per i controlli sull’attività lavorativa).
Questo binomio (divieto/limiti correlati al principio di trasparenza) caratterizza anche la disciplina della decisione algoritmica fondata su dati personali (art. 22 Reg. Ue 2016/679), la struttura generale dell’Artificial Intelligence Act e del draft di direttiva sul lavoro mediante piattaforma: tutte norme che possono offrire garanzie importanti a un mondo del lavoro che, con l’innesto dell’i.a., lascia emergere istanze di tutela nuove.
Il principio di trasparenza, che ne espressione, è stato recentemente valorizzato in quest’ambito dall’art. 4 d.lgs. 104/22, recante attuazione della direttiva (UE) 2019/1152, relativa a condizioni di lavoro trasparenti e prevedibili nell'Unione europea che ha introdotto, in capo al datore di lavoro, uno specifico onere informativo (limitato tuttavia dal d.l. 48/23 ai casi di automatizzazione integrale) relativo all’utilizzo di sistemi decisionali o di monitoraggio, di tipo automatizzato, nella gestione del rapporto di lavoro.
Si tratta, in particolare, di sistemi decisionali o di monitoraggio automatizzati “deputati a fornire indicazioni rilevanti ai fini della assunzione o del conferimento dell'incarico, della gestione o della cessazione del rapporto di lavoro, dell'assegnazione di compiti o mansioni nonché indicazioni incidenti sulla sorveglianza, la valutazione, le prestazioni e l'adempimento delle obbligazioni contrattuali dei lavoratori”. .
La previsione di tale onere informativo esteso anche alle rappresentanze sindacali fa, naturalmente, salvo quanto disposto dall’art. 4 della l. 300/1970 secondo cui, appunto, gli strumenti dai quali derivi anche la possibilità di controllo a distanza dell'attività dei lavoratori possono essere impiegati esclusivamente per esigenze organizzative e produttive, per la sicurezza del lavoro e per la tutela del patrimonio aziendale e possono essere installati previo accordo collettivo stipulato dalla rappresentanza sindacale unitaria o dalle rappresentanze sindacali aziendali ovvero su autorizzazione amministrativa.
Inoltre, al fine di verificare che gli strumenti utilizzati per lo svolgimento della prestazione lavorativa siano conformi alle disposizioni del Regolamento (UE) 2016/679, il datore di lavoro o il committente sono tenuti a effettuare una valutazione d'impatto privacy con eventuale consultazione preventiva del Garante.
Si tratta di una garanzia ulteriore rispetto a quella, trasversale, dell’art. 22 del Reg. (UE) 2016/679, che vieta l’assunzione di decisioni basate unicamente su trattamenti automatizzati, con effetti significativi sulla persona, in assenza di garanzie come il diritto a conoscere la logica utilizzata, a ottenere l’intervento umano e a non subire decisioni discriminatorie. Esso ha consentito al Garante di riconoscere importanti tutele anche in un ambito delicato quale quello del lavoro mediante piattaforma dei rider (Provv. n. 234 e 285 del 2021). L’Autorità ha, in particolare, valorizzato il diritto di ottenere l’intervento umano, esprimere la propria opinione e contestare la decisione algoritmica, prescrivendo anche misure volte a minimizzare il rischio di bias ed evitare usi impropri e discriminatori dei meccanismi reputazionali basati sui feedback.
Principi analoghi sono contenuti nel draft di direttiva europea sul lavoro mediante piattaforma, con particolari garanzie per i “dati biometrici, relativi a conversazioni private, a quelli da cui si evincano l'origine razziale o etnica, lo status di migrante, le opinioni politiche, le convinzioni religiose o filosofiche, la disabilità, lo stato di salute, emotivo o psicologico, l'adesione a un sindacato, la vita o l'orientamento sessuale”.
Una parziale anticipazione dei contenuti della direttiva era prevista da uno schema di ddl della scorsa legislatura su cui il Garante ha reso parere (n. 94/22), sostanzialmente analogo all’AS 280, di questa legislatura. Secondo il principio dell’“Human in command” esso imponeva, tra l’altro, alle piattaforme di monitorare periodicamente l'impatto delle decisioni automatizzate individuali prevedendo anche, in favore degli incaricati dello svolgimento di tali funzioni, forme di protezione contro il licenziamento o altre misure sfavorevoli connesse al mancato accoglimento delle decisioni algoritmiche. Si vietava, inoltre, l’utilizzo dei sistemi decisionali e di monitoraggio automatizzati in modo tale da pregiudicare la salute mentale e fisica dei lavoratori su piattaforma e si prevedeva l’informazione e la consultazione delle rappresentanze sindacali sul monitoraggio dell’i.a. e sui rischi anche discriminatorii suscettibili di derivarne.
Il dovere d’informazione dei rappresentanti dei lavoratori è previsto anche dall’Artificial Intelligence Act per i sistemi di i.a. ad alto rischio (art. 26, p.7), tra i quali quelli utilizzati a fini di selezione e valutazione del personale e adozione di decisioni riguardanti le condizioni del rapporto lavorativo. Inoltre, l’AI Act vieta, salvo eccezioni per usi sanitari o di sicurezza, l'uso di sistemi di i.a. per inferire le emozioni di una persona nel contesto lavorativo.
L’adeguamento dell’ordinamento interno all’AI Act, così come alla direttiva, da recepire una volta approvata, potrà rappresentare un’occasione importante per l’introduzione di garanzie ulteriori rispetto a quella generale di cui all’art. 22 del Regolamento (UE) 2016/679, ad esse complementare e comunque centrale nell’articolata cornice regolatoria dell’i.a., in un contesto così complesso quale quello lavorativo.
Il Garante offrirà naturalmente il proprio contributo consultivo al legislatore, anche alla luce dell’esperienza maturata sul terreno delicatissimo della tutela del lavoratore dai rischi connessi all’uso delle neotecnologie e all’elusione delle garanzie introdotte appunto, sin dal 1970, rispetto al potere datoriale.
Vi ringrazio.

