

Audizione del Presidente del Garante per la protezione dei dati personali, Prof. Pasquale Stanzione - Indagine conoscitiva sul tema della diffamazione anche in relazione ai nuovi strumenti tecnologici di comunicazione

Senato della Repubblica - 2a Commissione Giustizia 
(18 luglio 2023)
- IL VIDEO DELL'AUDIZIONE
Ringrazio la Commissione per aver inteso affrontare un tema di così notevole rilevanza, come quello della disciplina della diffamazione, anche nella prospettiva, solo apparentemente distante, della protezione dei dati personali. Le molteplici forme di tutela accordate dalla disciplina di protezione dei dati rappresentano, infatti, una risorsa sempre più importante a fronte della progressivamente maggiore diffusione, in rete, di contenuti diffamatori, fake news o di veri e propri discorsi d’odio.
Benché, infatti, non spetti al Garante, ma all’autorità giudiziaria, accertare il carattere diffamatorio di contenuti diffusi, la tutela che l’Autorità può accordare ben può riguardare dati trattati in violazione del principio di esattezza e quindi, eventualmente, anche diffamatori. La tutela, di natura essenzialmente remediale (e quindi in forma specifica), prevista dalla disciplina di protezione dei dati integra quella di tipo risarcitorio che può essere accordata in sede civilistica, o la sanzione penale conseguente all’accertamento giudiziale nella relativa sede.
Come ha, infatti, riconosciuto la giurisprudenza, pur non potendo l’Autorità sindacare la diffamatorietà dei contenuti contestati, rimessa alla competenza dell’autorità giudiziaria, essa può certamente valutare la liceità del trattamento realizzato con la diffusione dei dati in questione, ammettendosi espressamente la possibilità che si verifichino “sia una lesione del diritto al corretto trattamento dei dati personali sia una lesione del diritto all’onore, alla reputazione, all’immagine”. In tali casi, il Garante esamina la questione inerente l’onore soltanto come “conseguenza della lesione dell’identità personale (realizzata con un illecito trattamento di dati personali)” (Trib. Milano, sent. 7846 del 5 settembre 2018).
Il trattamento illecito di dati personali – in particolare, ma non esclusivamente, perché realizzato in violazione del principio di esattezza – legittima, infatti, l’interessato, all’esercizio del suo diritto alla rettifica e alla cancellazione, a tutela ad un tempo dell’identità e dignità del soggetto ma, anche, della correttezza e veridicità dell’informazione (artt. 16 e 17 Reg. Ue 2016/679).
Un particolare aspetto di questa tutela riguarda l’esercizio del diritto alla cancellazione nella forma (meglio nota come “diritto all’oblio”) della deindicizzazione di contenuti, appunto, a vario titolo inesatti o non aggiornati, con istanza rivolta al motore di ricerca e, in caso di inerzia o rigetto, al Garante o all’autorità giudiziaria ordinaria. Come già riconosciuto dalla Corte di giustizia nel caso Costeja-Google Spain del 13 maggio 2014, infatti, l’attività di indicizzazione realizzata dal motore di ricerca costituisce un trattamento di dati personali ulteriore, caratterizzato peraltro da un’attitudine “profilativa” particolarmente significativa. 
Rispetto a contenuti diffamatori, l’amplificazione della loro visibilità e la loro più agevole reperibilità garantite dall’attività di indicizzazione dei motori di ricerca aggravano, infatti, il pregiudizio suscettibile di derivare all’interessato dalla diffusione di tali informazioni. Per questo, la deindicizzazione di tali contenuti rappresenta una tutela complementare, ma essenziale, per la dignità, l’onore e la reputazione della persona, in un contesto in cui, sempre più, siamo ciò che “Google dice che siamo”, per riprendere una lucida notazione di Stefano Rodotà.
E se l’oblio, nella forma del delisting, si è tradizionalmente affermato come strumento di tutela tipico rispetto a contenuti veritieri e legittimamente diffusi in origine, ma superati dall’evoluzione dei fatti e non più corrispondenti alla loro attualità, esso incontra oggi applicazioni rilevanti anche rispetto a contenuti illecitamente diffusi, come quelli diffamatori. Nella citata sentenza, in particolare, il Tribunale di Milano riferisce, in maniera particolarmente significativa, la deindicizzazione – quale espressione del “diritto alla dis-associazione del proprio nome da un dato risultato di ricerca”- alla tutela dell’identità personale. La pronuncia osserva, infatti, che “il c.d. ridimensionamento della propria visibilità telematica rappresenta un aspetto “funzionale” del diritto all’identità personale, diverso dal diritto ad essere dimenticato, che coinvolge e richiede una valutazione di contrapposti interessi: quello dell’individuo a non essere (più) trovato on line e quello del motore di ricerca”.

Il Tribunale sembra, dunque, ammettere la deindicizzazione anche a tutela dell’esattezza dei dati trattati (in funzione di garanzia del diritto all’identità personale), in casi nei quali il decorso del tempo (elemento costitutivo dell’oblio) non rileva, come affermato peraltro dal Garante. Soluzione sostenuta, del resto, dal combinato disposto degli artt. 5, par.1, lett.a e d) e 17, par.1, lett. d) del Regolamento Ue 2016/679, oltre che dalle Linee guida n. 5 del 2019 del Comitato europeo per la protezione dei dati, che annoverano il carattere diffamatorio (giudizialmente accertato) dei contenuti, quale criterio da considerare ai fini dell’accoglimento delle istanze di deindicizzazione.
Recentemente, la Corte di Cassazione ha ulteriormente sviluppato questa linea interpretativa affermando, con l’ord. 18430 dell’8 giugno 2022, la responsabilità del motore di ricerca per omesso accoglimento dell’istanza di deindicizzazione del contenuto accertato come falso dall'autorità giudiziaria. La Corte rileva, infatti, come il prestatore di un servizio di hosting qual è il motore di ricerca risponda del contenuto delle informazioni diffuse, ai sensi dell’art. 16 dlgs 70 del 2003, quando: a) egli "sia effettivamente a conoscenza del fatto che l'attività o l'informazione è illecita" e per quanto attiene ad azioni risarcitorie "sia al corrente di fatti o di circostanze che rendono manifesta l'illiceità dell'attività o dell'informazione"; oppure b) egli non "agisca immediatamente per rimuovere le informazioni o per disabilitarne l'accesso" appena "a conoscenza di tali fatti, su comunicazione delle autorità competenti”.
La Corte di giustizia - con la sentenza dell’ 8 dicembre 2022, C-460/20, TU, RE c. Google -  in linea con la responsabilizzazione delle piattaforme promossa dal Digital Services Act - ha, peraltro, agevolato le condizioni per l’accoglimento delle istanze di deindicizzazione di contenuti falsi. Esse sono state, infatti, riconosciute sussistenti anche nel caso di manifesta inesattezza, non necessariamente sancita in sede giurisdizionale. Non si pretende, certo, che il motore di ricerca sia l’arbitro della verità dei contenuti indicizzati, ma gli si richiede uno scrutinio attento sull’eventuale loro manifesta inesattezza, segnalata dall’interessato.
La progressiva valorizzazione, almeno in sede pretoria, del delisting quale strumento di tutela non solo dell’identità, ma anche della dignità, dell’onore e della reputazione della persona, ben si motiva in ragione dell’amplificazione del pregiudizio derivante dall’indiscriminata reperibilità dei contenuti diffamatori, resa possibile dall’azione dei motori di ricerca. 

Come rilevato dalla Corte costituzionale, con la pronuncia n. 132 del 2020 (d’incostituzionalità, differita e poi dichiarata con sent. 150/21, dell’art. 13 l. 47/48), nella predisposizione delle “complessive strategie sanzionatorie in grado, da un lato, di evitare ogni indebita intimidazione dell’attività giornalistica; e, dall’altro, di assicurare un’adeguata tutela della reputazione individuale contro illegittime – e talvolta maliziose – aggressioni poste in essere nell’esercizio di tale attività”, vanno considerati anche “gli effetti di rapidissima e duratura amplificazione degli addebiti diffamatori determinata dai social networks e dai motori di ricerca in internet, il cui carattere lesivo per la vittima – in termini di sofferenza psicologica e di concreti pregiudizi alla propria vita privata, familiare, sociale, professionale, politica – e per tutte le persone a essa affettivamente legate risulta grandemente potenziato rispetto a quanto accadeva anche solo in un recente passato”.
Nell’ambito della “complessiva riforma della disciplina vigente” sollecitata dalla Corte costituzionale, nuovamente con la sent.150 del 2021, si potrebbe allora ulteriormente valorizzare questo tipo di tutele remediali, estendendole a un novero più ampio di lesione della dignità del soggetto, mediante contenuti diffusi on line in maniera manifestamente illecita. Come dimostrano i casi dell’oblio e del cyberbullismo, il meccanismo di notice and take down, fondato sulla richiesta al gestore di rimozione o deindicizzazione dei dati illecitamente trattati e la successiva istanza al Garante in caso di inerzia o rigetto, è infatti un utile strumento di tutela dei diritti della personalità on line. Esso coniuga, in particolare, l’esigenza della pronta rimozione dei contenuti (soprattutto in caso di adesione spontanea del provider) con la riserva all’autorità pubblica della decisione in ultima istanza, nel contraddittorio delle parti, sul bilanciamento tra gli interessi giuridici coinvolti.  
Questa soluzione risponde alle esigenze sottolineate dalla Corte di giustizia e dalla Corte europea dei diritti dell’uomo, quest’ultima in particolare con alcune sentenze che hanno sancito addirittura, in capo agli Stati, un obbligo positivo di assicurare misure idonee a tutelare la dignità personale (cfr., in particolare, Delfi c. Estonia del 2015).  
Si potrebbe dunque riflettere sull’estensione di tale disciplina a casi quali l’hate speech (come prevedevano la pdl Moretti AC 2047 della XVII legislatura e la pdl Boldrini, AC 2936, della XVIII, ora AC 259) o la diffusione di notizie manifestamente inesatte e lesive dell’identità individuale (analogamente a quanto previsto dal ddl Zanda, AS 3001, della XVII legislatura, per contenuti illeciti). In tal modo si consentirebbe al Garante di fornire una tutela effettiva alle vittime di questi illeciti, anche agendo direttamente sulle piattaforme (a rigore non qualificabili come titolari del trattamento realizzato dagli utenti sui loro profili), valorizzando la tendenza alla loro responsabilizzazione promossa appunto, come si è detto, dal Digital Services Act.
Le misure accordate dal Garante rispetto a contenuti manifestamente illeciti (perché ictu oculi inesatti o lesivi come i discorsi d’odio) ben potrebbero costituire parte di una strategia integrata di tutela della dignità personale, articolata su diversi livelli di protezione, proporzionali al grado della lesione subita.
Vi si potrebbe riflettere anche in sede di adeguamento al Digital Services Act, anche coordinando le competenze del Garante e di Agcom sulla rimozione di contenuti illeciti secondo quella prospettiva di leale collaborazione che già la prassi ha promosso, con risultati di rilievo.

