

Audizione del Presidente del Garante per la protezione dei dati personali, Prof. Pasquale Stanzione, sul disegno di legge n. 1066 (Norme per lo sviluppo e per l'adozione di tecnologie di intelligenza artificiale) 
Senato della Repubblica - 8a Commissione (Ambiente, transizione ecologica, energia, lavori pubblici, comunicazioni, innovazione tecnologica)
(22 aprile 2024)
- IL VIDEO DELL'AUDIZIONE
Ringrazio anzitutto - e non ritualmente- la Commissione per aver voluto acquisire all’istruttoria legislativa sul disegno di legge anche il punto di vista della protezione dei dati. Esso è importante tanto più rispetto all’i.a., anche perché il Regolamento generale sulla protezione dei dati, sin dal 2016, ha introdotto la prima disciplina dell’i.a. e del suo nucleo fondativo: il processo decisionale automatizzato.
L’art. 22 del Reg Ue 2016/679 ha infatti sancito sul punto specifiche garanzie, quali il principio di conoscibilità (che esclude la legittimità di algoritmi black-box riconoscendo il diritto di ricevere informazioni significative sulla logica utilizzata), quello di non esclusività della decisione algoritmica che impone un intervento umano capace di controllare, validare o smentire la decisione automatizzata, il divieto di discriminazione algoritmica, un generale principio di trasparenza che impone precisi obblighi informativi nei confronti dell’utente, un criterio di qualità ed esattezza dei dati da utilizzare, particolarmente rilevante per evitare i bias propri di un addestramento dell’algoritmo sulla base di informazioni inesatte o non sufficientemente rappresentative.
I principi sanciti dalla disciplina privacy hanno, così, già assunto un valore determinante nella regolazione dei processi algoritmici, al punto da aver consentito, ad esempio alla giurisprudenza amministrativa, di rinvenirvi la disciplina di alcune determinate fattispecie e appunto, al Garante, di conformare l’utilizzo dell’i.a. con i valori propri dell’ordinamento costituzionale ed europeo. 
Questo spiega non solo perché l’AI Act si fondi anche sull’art. 16 TFUE (base giuridica della normativa in materia di protezione dati) ma, soprattutto, perché mutui, dal Reg. Ue 2016/679, molte opzioni di politica legislativa: ad esempio la tassonomia dei divieti e delle regole applicabili, fondata sul grado di rischiosità dei sistemi, la valutazione d’impatto (qui sui diritti fondamentali) per le applicazioni ad alto rischio, il principio di trasparenza quale cardine del rapporto tra utilizzo della tecnica e autodeterminazione della persona, le garanzie rafforzate per i dati “sensibili” (recte: appartenenti a categorie particolari), il sistema dei diritti, delle tutele e delle sanzioni, la governance nella sua duplice dimensione interna e sovranazionale.
Il ddl in esame anticipa alcuni dei temi trattati dall’AI Act rispetto al quale deve dunque valutarsi la conformità.
Premesso, dunque, l’invito a una più generale riflessione sull’opportunità di normare, con disposizioni interne, aspetti già compresi nell’AI Act e diversi da quelli di politica industriale e del lavoro sottesi agli art. 2 e 3, sui quali il legislatore interno conserva piena discrezionalità, si analizzeranno di seguito alcuni contenuti specifici del disegno di legge.
Dal punto di vista della protezione dei dati rilevano, in particolare, le norme di cui agli artt. 4, 5 e 6.
Art. 4
La valutazione preliminare da compiere è la rispondenza dell’art. 4 ai requisiti complessi sanciti dagli artt 57 ss dell’AI Act per le sandbox, considerando però come i suoi contenuti di dettaglio siano rimessi ad atti esecutivi della Commissione proprio al fine di garantire, come recita l’alinea dell’art. 58, uniformità normativa all’interno dell’Unione e non frustrare, conseguentemente, le esigenze di omogeneità sottese alla stessa scelta della forma regolamentare.
Per quanto poi concerne il merito della disciplina, esigenze di conformità all’AI Act imporrebbero di modulare il contenuto della relazione che le Autorità coinvolte sono tenute a svolgere (comma 6) a quello, più ampio, previsto dall’art. 57, p. 16, dell’AI Act, rafforzando così gli obblighi di trasparenza.
Ancora, la clausola di invarianza finanziaria di cui al comma 8 pare difficilmente compatibile con il disposto dell’art. 57, p.4, AI Act, oltre che frutto di una sottostima degli adempimenti amministrativi connessi alla realizzazione della sandbox.
Inoltre, il contenuto dei provvedimenti delle Autorità coinvolte (comma 5, terzo periodo) dovrebbe includere anche la disciplina dell’esercizio dei poteri inibitori nei casi di cui al comma 7, ultimo periodo, per circoscriverne la discrezionalità a garanzia di cittadini e imprese, oltre che per esigenze di conformità all’AI Act.
Alcune perplessità suscita poi il regime speciale del segreto d’ufficio di cui agli ultimi due periodi del comma 5, caratterizzato peraltro da scarsa determinatezza in quanto esteso onnicomprensivamente a “attività, notizie, informazioni, dati (…) relativ[i] alla sperimentazione”.    Esso, infatti, non trova riscontro né nella disciplina delle sandbox contenuta nell’AI Act (cfr artt. 57, p. 8 e 78) né in quella interna (art. 36 d.l. 76/20, richiamato in termini derogatori quanto al termine di durata della sperimentazione) e pare difficilmente compatibile con il principio di trasparenza espresso dall’obbligo di relazione sancito, in conformità con l’AI Act, al comma 6.
Peraltro, l’inopponibilità giudiziale del segreto prevista dall’ultimo periodo appare eccessivamente ristretta, anche in ragione dell’esigenza di garantire la tutela civile conformemente alle esigenze espresse dall’art. 57, p. 12 dell’AI Act. Per altro verso, anche rispetto all’inopponibilità del segreto andrebbe chiarita l’insindacabilità, da parte dell’amministrazione richiesta, della valutazione di necessità del dato ai fini processuali, pena una sostanziale violazione del disposto di cui agli artt.101, c.II e 104 Cost.
Gli ultimi due periodi del comma 5 andrebbero, pertanto, soppressi.
Art. 5
Anche l’art. 5 disciplina un tema, quale quello dell’i.a. generativa e dei correlativi obblighi di trasparenza, normato dagli art. 51 ss dell’AI Act, anche rispetto all’etichettatura (art. 50 AI Act).
La sovrapposizione dell’oggetto delle due discipline è tale, dunque, da far ritenere preclusa al legislatore interno (o estremamente limitata) un’autonoma normazione sul punto.
Art. 6
La norma introduce una disciplina specifica per l’uso delle repliche digitali, che presenta significativi punti d’intersezione sia con l’art. 50 AI Act, sia con la disciplina di protezione dati personali, almeno rispetto a tutte le ipotesi (presumibilmente non rare) in cui la replica involga, anche solo in parte, dati personali. Vengono in rilievo, in particolare (ma ovviamente non solo) norme di garanzia quali quella di cui all’art. 2-terdecies d.lgs. 196 del 2003 sull’esercizio postmortale dei diritti rispetto al trattamento e quelle sanzionatorie, amministrative e penali, relative tra l’altro al trattamento illecito di dati personali.
La relazione tra queste due discipline va, dunque, regolata attraverso, quantomeno, una clausola di salvaguardia in favore della normativa di protezione dei dati. Essa contribuirebbe, infatti, a evitare possibili dubbi interpretativi in ordine all’assorbimento da parte di questa disposizione - per consunzione o specialità unilaterale- delle implicazioni di protezione dei dati connesse alle repliche digitali.
Quella della coerenza tra i vari plessi normativi è, del resto, un’esigenza che connota in maniera particolare la disciplina delle neotecnologie, caratterizzata spesso- nella rincorsa del diritto rispetto a una tecnica in costante e troppo rapido mutamento – da sovrapposizioni non solo a livello interno, tra norme di diverso settore ma anche a livello sovranazionale, tra disposizioni interne ed europee.
Ed essendo la regolazione del digitale materia che caratterizza, in misura significativa, la politica del diritto dell’Unione europea, lo sforzo cui è chiamato il legislatore interno è quello di un confronto costante con la disciplina europea, per individuare limiti e opzioni della propria discrezionalità.
Questo vale anche in riferimento all’annunciato d.d.l. governativo sull’i.a., rispetto al cui esame il Garante offre sin d’ora la propria piena disponibilità al confronto che il Parlamento e il Governo dovessero richiedere. E questo, anche considerando l’obbligo di consultazione del Garante su questo tipo di atti normativi sancito, espressamente, dall’art. 36, p.4, del Reg. Ue 2016/679.
Vi ringrazio.

