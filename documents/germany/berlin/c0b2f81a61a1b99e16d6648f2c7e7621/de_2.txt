During the conference of Commissioners for Freedom of Information in Germany on the 16th of 
October 2018 in Ulm, the following commissioners adopted the position paper 

 

“Transparence of public administration using algorithms is indispensable for the protection of basic 

human and civil rights” 

The Federal Commissioner for Data Protection and Information freedom, 

- 
-  Berlin’s Commissioner for Data Protection and Freedom of Information, 

-  Bremen’s Commissioner for Data Protection and Freedom of Information, 

-  Mecklenburg-Western Pomerania’s Commissioner for Data Protection and Freedom of 

Information, 

-  Rhineland-Palatinate’s Commissioner for Data Protection and Freedom of Information, 

- 

- 

Saxony-Anhalt’s Commissioner for Data Protection and Freedom of Information, 

Schleswig-Holstein’s Commissioner for Freedom of Information, 

Thuringia’s Commissioner for Data Protection and Freedom of Information, and 

- 
-  Baden-Wuerttemberg’s Commissioner for Data Protection and Freedom of Information. 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

 

Position Paper 

 

“Transparence of public administration using algorithms is indispensable for the protection of basic 

human and civil rights” 

 

Already today, some decisions in public institutions are made by automated data processes, aided by 

algorithms and artificial intelligence (KI), not only in a preparatory phase, but also for the decision 
itself.  

The usage of algorithms and KI can make things more efficient and the evaluation of large amounts 

of data can become easier or would not be possible without. But the administration carries a high 
responsibility, to make sure, the state’s decisions abide by the law. The public administration is 

especially obliged to respect the basic values of our constitution.  This respect is important, if it wants 

to keep the citizen’s trust. This is essential for the functioning of our state. Respecting Human 

Dignity, and the imperative of anti-discrimination are fundamental. Having this in mind, it is very 
problematic, that most algorithms and KI’s function in an absolutely intransparent manner. The 

affected citizen can usually not oversee, what the input into the decision making is: which kinds of 

data and moral values the systems are fed with, and in how far the outcome is lawful. This is why the 

used algorithms and KI-procedures must be made transparent for citizens, and the administration 
itself has to be put in a position to understand their own procedures as well. 

Aside from automated decisions that concern citizens, other decisions such as the planning of traffic 

infrastructure, or fiscal decisions must remain comprehensible too.  

The higher the risk of a substantially important and possibly negative outcome for the people 

concerned, the stricter it must be examined, if algorithms and KI-procedures can be used in a manner 
that respects the constitution, or if they can be implemented in a lawful way and which 

consequences they may have. Transparency is indispensable for this kind of impact assessment. Also, 

the calculated results have to be predictable and comprehendible; similar requests must lead to a 

similar outcome.  

Following the principles of informational freedom and transparency of public administration, the 

essential Information regarding the used algorithms and KI used must be made available to the 

public.  

The Commissioners for Informational Freedom in support of this paper therefore demand that the 

federal, as well as various state legislators, commit all public institutions to a transparent and 

responsible handling of algorithms and KI-Procedures. It makes sense to embed such provisions on 
transparency in the respective laws on transparency and informational freedom, or in the respective 

applicable laws. Exceptions should be kept to a minimum.  

 

So specifically, following requirements should be urgently implemented:  

 

- 

Public Institutions must evaluate, before using algorithms and KI-Procedures, in how far their 

use can be in consent with the constitution. If, after a prudent evaluation, doubts remain, 
especially if the procedures will not be comprehensible, transparent and controllable, they 

may not be used.  

- 

Public institutions must take care, that the algorithms are sufficiently transparent. For a 

controllable usage, they must have informative, comprehensive and generally applicable 

Information at hand. This comprises:  

o  The categories of data being used 
o  The logic in the procedures, the formulas, and the emphasis that the factors have on 

the outcome, information about the knowledge and individual configuration of the 

users 

o  The consequences of decisions based on the procedures.  

As far as this is legally possible, this information should be published.  

- 

To make sure the public administration can fulfill this, this should be kept in mind during 

programming (Transparency by design)  

- 

The output data must be complemented by the information, which was especially important 
for the decision. Especially self-learning systems must be supported by tools to evaluate their 

process.  

- 

The documentation of the processes as well as their essential parameters are indispensable, 

to instate the security and trust in them. Technological and organizational measures must be 

instated to prevent manipulation. These also have to be evaluated on a regular basis. To 
make comprehensive controls possible, public intuitions must be able to check the source 

code by themselves. This must apply to other relevant information used in these processes 

as well.  

- 

Public institutions must take security measures, adequate to the probable risks. Depending 
on the individual case, manual controls, or the taking back of decisions can be ways of 

handling this.  

- 

The procedures may under no circumstance discriminate. This must be kept in mind while 

development, and when choosing the types of training data for self-learning systems.  
In any case, if there are high risks for citizens, an impact assessment must preceed the 

- 

decision over wether or not to use algorithms or KI-procedures. If substantial changes occur, 

as it will be the case with self-learning systems, this must be repeated. In especially sensitive 

areas these procedures should only be implemented after special certifications.  

The legislation and the public administration must be aware, that these standards are obligatory and 

have to be implemented, due to the lawfulness of the administration and the administratin’s 

obligation to the constitution. Above that, the legislation must implement these standards in the 
private sector as well.  

 

 

 

 

 

 

